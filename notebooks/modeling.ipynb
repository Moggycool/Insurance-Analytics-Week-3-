{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Modeling Results Analysis\n",
    "# ## AlphaCare Insurance Solutions (ACIS)\n",
    "# \n",
    "# This notebook analyzes the results from the `modeling.py` pipeline.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# %%\n",
    "# Set project paths\n",
    "PROJECT_ROOT = Path(\"D:/Python/Week-3/Insurance-Analytics-Week-3-\").resolve()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Set data paths\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"claim_data_prepared.csv\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "REGRESSION_DIR = MODELS_DIR / \"regression\"\n",
    "CLASSIFICATION_DIR = MODELS_DIR / \"classification\"\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Data file exists: {DATA_PATH.exists()}\")\n",
    "print(f\"Models directory exists: {MODELS_DIR.exists()}\")\n",
    "print(f\"Reports directory: {REPORTS_DIR}\")\n",
    "\n",
    "# %%\n",
    "# Load the prepared data\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# Show basic info\n",
    "print(\"\\nFirst 10 columns:\")\n",
    "for i, col in enumerate(df.columns[:10]):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTarget columns present:\")\n",
    "for target in ['TotalClaims', 'Log_TotalClaims', 'HighClaim', 'ClaimSeverityCategory']:\n",
    "    if target in df.columns:\n",
    "        print(f\"  ‚úì {target}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {target}\")\n",
    "\n",
    "# %%\n",
    "# Basic data statistics\n",
    "print(\"BASIC DATA STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'TotalClaims' in df.columns:\n",
    "    print(\"\\nTotalClaims Distribution:\")\n",
    "    print(f\"Total policies: {len(df):,}\")\n",
    "    print(f\"Policies with claims (>0): {(df['TotalClaims'] > 0).sum():,} ({(df['TotalClaims'] > 0).mean()*100:.2f}%)\")\n",
    "    print(f\"Policies with zero claims: {(df['TotalClaims'] == 0).sum():,} ({(df['TotalClaims'] == 0).mean()*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nClaim Amount Statistics (for policies with claims):\")\n",
    "    claims_df = df[df['TotalClaims'] > 0]\n",
    "    print(f\"Mean claim: ${claims_df['TotalClaims'].mean():,.2f}\")\n",
    "    print(f\"Median claim: ${claims_df['TotalClaims'].median():,.2f}\")\n",
    "    print(f\"Std claim: ${claims_df['TotalClaims'].std():,.2f}\")\n",
    "    print(f\"Min claim: ${claims_df['TotalClaims'].min():,.2f}\")\n",
    "    print(f\"Max claim: ${claims_df['TotalClaims'].max():,.2f}\")\n",
    "\n",
    "if 'HighClaim' in df.columns:\n",
    "    print(f\"\\nHighClaim Distribution:\")\n",
    "    print(f\"High claims: {df['HighClaim'].sum():,} ({df['HighClaim'].mean()*100:.2f}%)\")\n",
    "    print(f\"Non-high claims: {(df['HighClaim'] == 0).sum():,} ({(df['HighClaim'] == 0).mean()*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d22e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Visualize data distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: TotalClaims distribution (log scale)\n",
    "if 'TotalClaims' in df.columns:\n",
    "    axes[0, 0].hist(df[df['TotalClaims'] > 0]['TotalClaims'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_xlabel('Claim Amount ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Claim Amounts (Claims > 0)')\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Claims vs No Claims\n",
    "if 'TotalClaims' in df.columns:\n",
    "    claim_status = ['No Claims', 'Has Claims']\n",
    "    claim_counts = [(df['TotalClaims'] == 0).sum(), (df['TotalClaims'] > 0).sum()]\n",
    "    colors = ['lightcoral', 'lightgreen']\n",
    "    axes[0, 1].bar(claim_status, claim_counts, color=colors, edgecolor='black')\n",
    "    axes[0, 1].set_ylabel('Number of Policies')\n",
    "    axes[0, 1].set_title('Policies with vs without Claims')\n",
    "    for i, v in enumerate(claim_counts):\n",
    "        axes[0, 1].text(i, v + max(claim_counts)*0.01, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 3: HighClaim distribution\n",
    "if 'HighClaim' in df.columns:\n",
    "    high_claim_counts = df['HighClaim'].value_counts()\n",
    "    labels = ['Non-High Claim', 'High Claim']\n",
    "    colors = ['lightblue', 'salmon']\n",
    "    axes[1, 0].bar(labels, high_claim_counts.values, color=colors, edgecolor='black')\n",
    "    axes[1, 0].set_ylabel('Number of Policies')\n",
    "    axes[1, 0].set_title('High Claim Distribution')\n",
    "    for i, v in enumerate(high_claim_counts.values):\n",
    "        axes[1, 0].text(i, v + max(high_claim_counts.values)*0.01, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 4: Log_TotalClaims distribution (if exists)\n",
    "if 'Log_TotalClaims' in df.columns and (df['TotalClaims'] > 0).sum() > 0:\n",
    "    axes[1, 1].hist(df[df['TotalClaims'] > 0]['Log_TotalClaims'], bins=30, edgecolor='black', alpha=0.7, color='gold')\n",
    "    axes[1, 1].set_xlabel('Log(TotalClaims)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of Log-Transformed Claims')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e14d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### 2. Import and Use the Modeling Module\n",
    "\n",
    "# %%\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# Try to import the modeling module\n",
    "try:\n",
    "    from src.modelling.modeling import(\n",
    "        load_data, build_preprocessor,\n",
    "        train_regression_models, train_classification_models,\n",
    "        run_pipeline, select_features\n",
    "    )\n",
    "    print(\"‚úÖ Successfully imported modeling module\")\n",
    "    \n",
    "    # You can now use functions from your modeling module\n",
    "    # For example, load data using your function:\n",
    "    df_from_module = load_data(str(DATA_PATH))\n",
    "    print(f\"Loaded data shape via module: {df_from_module.shape}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Could not import modeling module: {e}\")\n",
    "    print(\"\\nMake sure you're running from the correct directory or\")\n",
    "    print(\"the module structure is correct.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3. Load and Analyze Model Results\n",
    "\n",
    "# %%\n",
    "# Load metadata\n",
    "metadata_path = MODELS_DIR / \"model_metadata.json\"\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(\"Model Metadata:\")\n",
    "    print(json.dumps(metadata, indent=2))\n",
    "else:\n",
    "    metadata = {}\n",
    "    print(\"No metadata file found\")\n",
    "\n",
    "# %%\n",
    "# Load all available models\n",
    "print(\"\\nLoading saved models...\")\n",
    "\n",
    "# Load regression models\n",
    "reg_models = {}\n",
    "if REGRESSION_DIR.exists():\n",
    "    print(f\"\\nRegression models in {REGRESSION_DIR}:\")\n",
    "    for pkl_file in REGRESSION_DIR.glob(\"*.pkl\"):\n",
    "        try:\n",
    "            model = joblib.load(pkl_file)\n",
    "            model_name = pkl_file.stem.replace('reg_', '')\n",
    "            reg_models[model_name] = {\n",
    "                'model': model,\n",
    "                'path': pkl_file,\n",
    "                'type': 'regression'\n",
    "            }\n",
    "            print(f\"  ‚úì {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error loading {pkl_file.name}: {e}\")\n",
    "\n",
    "# Load classification models\n",
    "clf_models = {}\n",
    "if CLASSIFICATION_DIR.exists():\n",
    "    print(f\"\\nClassification models in {CLASSIFICATION_DIR}:\")\n",
    "    for pkl_file in CLASSIFICATION_DIR.glob(\"*.pkl\"):\n",
    "        try:\n",
    "            model = joblib.load(pkl_file)\n",
    "            model_name = pkl_file.stem.replace('clf_', '')\n",
    "            clf_models[model_name] = {\n",
    "                'model': model,\n",
    "                'path': pkl_file,\n",
    "                'type': 'classification'\n",
    "            }\n",
    "            print(f\"  ‚úì {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error loading {pkl_file.name}: {e}\")\n",
    "\n",
    "# Load other models from root models directory\n",
    "other_models = {}\n",
    "print(f\"\\nOther models in {MODELS_DIR}:\")\n",
    "for pkl_file in MODELS_DIR.glob(\"*.pkl\"):\n",
    "    if pkl_file.parent == MODELS_DIR:  # Only root level\n",
    "        try:\n",
    "            model = joblib.load(pkl_file)\n",
    "            model_name = pkl_file.stem\n",
    "            other_models[model_name] = {\n",
    "                'model': model,\n",
    "                'path': pkl_file,\n",
    "                'type': 'other'\n",
    "            }\n",
    "            print(f\"  ‚úì {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error loading {pkl_file.name}: {e}\")\n",
    "\n",
    "# %%\n",
    "# Performance metrics from your modeling.py output\n",
    "regression_performance = {\n",
    "    'linear': {'rmse': 1.0311, 'r2': 0.6068},\n",
    "    'rf': {'rmse': 1.0046, 'r2': 0.6268},\n",
    "    'xgb': {'rmse': 1.0730, 'r2': 0.5742}\n",
    "}\n",
    "\n",
    "classification_performance = {\n",
    "    'logistic': {'auc': 0.9953, 'accuracy': 0.9975},\n",
    "    'rf': {'auc': 0.9891, 'accuracy': 0.9982},\n",
    "    'xgb': {'auc': 0.9697, 'accuracy': 0.9987}\n",
    "}\n",
    "\n",
    "# Visualize performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Regression RMSE\n",
    "models_reg = list(regression_performance.keys())\n",
    "rmse_values = [regression_performance[m]['rmse'] for m in models_reg]\n",
    "bars1 = axes[0, 0].bar(models_reg, rmse_values, color=['#1f77b4', '#2ca02c', '#ff7f0e'], edgecolor='black')\n",
    "axes[0, 0].set_ylabel('RMSE')\n",
    "axes[0, 0].set_title('Regression Models: RMSE\\n(Lower is Better)')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars1, rmse_values):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.02,\n",
    "                   f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Regression R¬≤\n",
    "r2_values = [regression_performance[m]['r2'] for m in models_reg]\n",
    "bars2 = axes[0, 1].bar(models_reg, r2_values, color=['#1f77b4', '#2ca02c', '#ff7f0e'], edgecolor='black')\n",
    "axes[0, 1].set_ylabel('R¬≤ Score')\n",
    "axes[0, 1].set_title('Regression Models: R¬≤ Score\\n(Higher is Better)')\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars2, r2_values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.02,\n",
    "                   f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Classification AUC\n",
    "models_clf = list(classification_performance.keys())\n",
    "auc_values = [classification_performance[m]['auc'] for m in models_clf]\n",
    "bars3 = axes[1, 0].bar(models_clf, auc_values, color=['#d62728', '#9467bd', '#8c564b'], edgecolor='black')\n",
    "axes[1, 0].set_ylabel('AUC Score')\n",
    "axes[1, 0].set_title('Classification Models: AUC\\n(Higher is Better)')\n",
    "axes[1, 0].set_ylim(0.9, 1.0)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars3, auc_values):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.001,\n",
    "                   f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Classification Accuracy\n",
    "acc_values = [classification_performance[m]['accuracy'] for m in models_clf]\n",
    "bars4 = axes[1, 1].bar(models_clf, acc_values, color=['#d62728', '#9467bd', '#8c564b'], edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_title('Classification Models: Accuracy\\n(Higher is Better)')\n",
    "axes[1, 1].set_ylim(0.99, 1.0)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars4, acc_values):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.0005,\n",
    "                   f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742974f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### 4. Feature Importance Analysis\n",
    "\n",
    "# %%\n",
    "def extract_feature_importance(model_dict, model_name):\n",
    "    \"\"\"Extract feature importance from a model.\"\"\"\n",
    "    model_info = model_dict.get(model_name)\n",
    "    if not model_info:\n",
    "        return None\n",
    "    \n",
    "    model = model_info['model']\n",
    "    \n",
    "    # Handle pipeline\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        # Get the estimator (last step)\n",
    "        estimator_name = list(model.named_steps.keys())[-1]\n",
    "        estimator = model.named_steps[estimator_name]\n",
    "        \n",
    "        # Get feature names from preprocessor if available\n",
    "        if 'pre' in model.named_steps:\n",
    "            preprocessor = model.named_steps['pre']\n",
    "            try:\n",
    "                feature_names = preprocessor.get_feature_names_out()\n",
    "            except:\n",
    "                feature_names = None\n",
    "    else:\n",
    "        estimator = model\n",
    "        feature_names = None\n",
    "    \n",
    "    # Extract importance based on model type\n",
    "    if hasattr(estimator, 'feature_importances_'):\n",
    "        importance = estimator.feature_importances_\n",
    "    elif hasattr(estimator, 'coef_'):\n",
    "        importance = np.abs(estimator.coef_.flatten())\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'importance': importance,\n",
    "        'feature_names': feature_names,\n",
    "        'model_type': model_info['type']\n",
    "    }\n",
    "\n",
    "# Extract feature importance from Random Forest regression\n",
    "rf_importance = extract_feature_importance(reg_models, 'rf')\n",
    "\n",
    "if rf_importance and rf_importance['feature_names'] is not None:\n",
    "    # Create DataFrame\n",
    "    feat_df = pd.DataFrame({\n",
    "        'feature': rf_importance['feature_names'],\n",
    "        'importance': rf_importance['importance']\n",
    "    }).sort_values('importance', ascending=False).head(20)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(feat_df['feature'][::-1], feat_df['importance'][::-1], color='teal')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 20 Features for Claim Severity Prediction\\n(Random Forest Regression)')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 Features for Claim Severity Prediction:\")\n",
    "    print(feat_df.head(10).to_string(index=False))\n",
    "\n",
    "# Extract feature importance from Random Forest classification\n",
    "if 'rf' in clf_models:\n",
    "    rf_clf_importance = extract_feature_importance(clf_models, 'rf')\n",
    "    \n",
    "    if rf_clf_importance and rf_clf_importance['feature_names'] is not None:\n",
    "        # Create DataFrame\n",
    "        feat_df = pd.DataFrame({\n",
    "            'feature': rf_clf_importance['feature_names'],\n",
    "            'importance': rf_clf_importance['importance']\n",
    "        }).sort_values('importance', ascending=False).head(20)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(feat_df['feature'][::-1], feat_df['importance'][::-1], color='coral')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Top 20 Features for Claim Probability Prediction\\n(Random Forest Classification)')\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Top 10 Features for Claim Probability Prediction:\")\n",
    "        print(feat_df.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### 5. SHAP Analysis for Model Interpretability\n",
    "\n",
    "# %%\n",
    "# Check SHAP availability\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "    print(f\"‚úÖ SHAP version: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    HAS_SHAP = False\n",
    "    print(\"‚ùå SHAP not installed. Install with: pip install shap\")\n",
    "\n",
    "# Helper function to convert numpy types to JSON-serializable\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Convert numpy/pandas objects to JSON-serializable types.\"\"\"\n",
    "    if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.Series):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.DataFrame):\n",
    "        return obj.to_dict()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# %%\n",
    "# SIMPLE SHAP FOR REGRESSION\n",
    "if HAS_SHAP and 'rf' in reg_models:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SHAP ANALYSIS - REGRESSION MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Load the model\n",
    "    rf_model = reg_models['rf']['model']\n",
    "    \n",
    "    # Prepare small sample\n",
    "    df_sev = df[df['TotalClaims'] > 0].copy()\n",
    "    X_sev = df_sev.drop(columns=['TotalClaims', 'Log_TotalClaims', 'Sqrt_TotalClaims',\n",
    "                                 'Std_TotalClaims', 'HighClaim', 'ClaimSeverityCategory', \n",
    "                                 'StratifyBin', 'PolicyID'], errors='ignore')\n",
    "    \n",
    "    # Take very small sample for stability\n",
    "    sample_size = min(50, len(X_sev))\n",
    "    X_sample = X_sev.sample(sample_size, random_state=42)\n",
    "    \n",
    "    print(f\"Using {sample_size} samples for SHAP analysis\")\n",
    "    \n",
    "    # Extract estimator from pipeline\n",
    "    if hasattr(rf_model, 'named_steps'):\n",
    "        # Get the RandomForest estimator\n",
    "        estimator = rf_model.named_steps.get('rf')\n",
    "        if estimator is None:\n",
    "            # Get the last estimator\n",
    "            estimator_name = list(rf_model.named_steps.keys())[-1]\n",
    "            estimator = rf_model.named_steps[estimator_name]\n",
    "    else:\n",
    "        estimator = rf_model\n",
    "    \n",
    "    # Convert categorical columns to numeric for SHAP\n",
    "    X_sample_numeric = X_sample.copy()\n",
    "    for col in X_sample_numeric.select_dtypes(include=['object', 'category']).columns:\n",
    "        X_sample_numeric[col] = pd.factorize(X_sample_numeric[col])[0]\n",
    "    \n",
    "    print(f\"Processed data shape: {X_sample_numeric.shape}\")\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(estimator)\n",
    "        \n",
    "        # Calculate SHAP values\n",
    "        shap_values = explainer.shap_values(X_sample_numeric.values)\n",
    "        \n",
    "        # Get expected value\n",
    "        if isinstance(explainer.expected_value, np.ndarray):\n",
    "            expected_value = float(explainer.expected_value[0])\n",
    "        else:\n",
    "            expected_value = float(explainer.expected_value)\n",
    "        \n",
    "        print(f\"SHAP calculation successful!\")\n",
    "        print(f\"Expected value: {expected_value:.4f}\")\n",
    "        \n",
    "        # Create simple feature importance plot\n",
    "        shap_importance = np.abs(shap_values).mean(0)\n",
    "        top_indices = np.argsort(shap_importance)[-10:][::-1]\n",
    "        \n",
    "        # Create manual bar plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        top_features = [X_sample.columns[i] for i in top_indices[:10]]\n",
    "        top_importance = shap_importance[top_indices[:10]]\n",
    "        \n",
    "        bars = plt.barh(top_features[::-1], top_importance[::-1], color='teal')\n",
    "        plt.xlabel('Mean Absolute SHAP Value')\n",
    "        plt.title('Top 10 Feature Importance (SHAP) - Regression Model')\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REPORTS_DIR / \"shap_regression_importance.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'top_features': top_features,\n",
    "            'shap_importance': top_importance.tolist(),\n",
    "            'expected_value': expected_value,\n",
    "            'sample_size': sample_size,\n",
    "            'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame({\n",
    "            'Feature': top_features,\n",
    "            'SHAP_Importance': top_importance\n",
    "        })\n",
    "        \n",
    "        print(\"\\nüìä TOP 10 FEATURES BY SHAP IMPORTANCE (Regression):\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # Save to files\n",
    "        results_df.to_csv(REPORTS_DIR / \"shap_regression_results.csv\", index=False)\n",
    "        with open(REPORTS_DIR / \"shap_regression_results.json\", 'w') as f:\n",
    "            json.dump(convert_to_serializable(results), f, indent=2)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Results saved to {REPORTS_DIR}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SHAP calculation failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå SHAP not available or regression model not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# TRADITIONAL FEATURE IMPORTANCE FOR CLASSIFICATION\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE - CLASSIFICATION MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'rf' in clf_models:\n",
    "    # Get the model\n",
    "    clf_model = clf_models['rf']['model']\n",
    "    \n",
    "    # Extract RandomForest estimator\n",
    "    if hasattr(clf_model, 'named_steps'):\n",
    "        estimator = clf_model.named_steps.get('rf')\n",
    "        if estimator is None:\n",
    "            estimator_name = list(clf_model.named_steps.keys())[-1]\n",
    "            estimator = clf_model.named_steps[estimator_name]\n",
    "    else:\n",
    "        estimator = clf_model\n",
    "    \n",
    "    # Get traditional feature importance\n",
    "    if hasattr(estimator, 'feature_importances_'):\n",
    "        # We need feature names - let's get them from the data\n",
    "        X_clf = df.drop(columns=['TotalClaims', 'Log_TotalClaims', 'Sqrt_TotalClaims',\n",
    "                                 'Std_TotalClaims', 'HighClaim', 'ClaimSeverityCategory',\n",
    "                                 'StratifyBin', 'PolicyID'], errors='ignore')\n",
    "        \n",
    "        # Take a small sample\n",
    "        X_sample_clf = X_clf.sample(min(100, len(X_clf)), random_state=42)\n",
    "        \n",
    "        # Convert categorical to numeric\n",
    "        for col in X_sample_clf.select_dtypes(include=['object', 'category']).columns:\n",
    "            X_sample_clf[col] = pd.factorize(X_sample_clf[col])[0]\n",
    "        \n",
    "        feature_importance = estimator.feature_importances_\n",
    "        \n",
    "        # Match with feature names\n",
    "        if len(feature_importance) == len(X_sample_clf.columns):\n",
    "            feature_names = X_sample_clf.columns.tolist()\n",
    "        else:\n",
    "            feature_names = [f\"feature_{i}\" for i in range(len(feature_importance))]\n",
    "        \n",
    "        # Get top features\n",
    "        top_indices = np.argsort(feature_importance)[-10:][::-1]\n",
    "        top_features = [feature_names[i] for i in top_indices[:10]]\n",
    "        top_importance = feature_importance[top_indices[:10]]\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bars = plt.barh(top_features[::-1], top_importance[::-1], color='coral')\n",
    "        plt.xlabel('Feature Importance Score')\n",
    "        plt.title('Top 10 Feature Importance - Classification Model')\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REPORTS_DIR / \"classification_feature_importance.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save results\n",
    "        results_df = pd.DataFrame({\n",
    "            'Feature': top_features,\n",
    "            'Importance': top_importance\n",
    "        })\n",
    "        \n",
    "        print(\"\\nüìä TOP 10 FEATURES BY TRADITIONAL IMPORTANCE (Classification):\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        results_df.to_csv(REPORTS_DIR / \"classification_feature_importance.csv\", index=False)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Results saved to {REPORTS_DIR}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Model doesn't have feature_importances_ attribute\")\n",
    "else:\n",
    "    print(\"‚ùå Classification model not found\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 6. Business Implications: Premium Calculation\n",
    "\n",
    "# %%\n",
    "def calculate_premium(p_claim, expected_severity, expense_ratio=0.15, profit_margin=0.10):\n",
    "    \"\"\"Calculate risk-based premium.\"\"\"\n",
    "    pure_premium = p_claim * expected_severity\n",
    "    premium_with_expenses = pure_premium * (1 + expense_ratio)\n",
    "    final_premium = premium_with_expenses * (1 + profit_margin)\n",
    "    \n",
    "    return {\n",
    "        'pure_premium': pure_premium,\n",
    "        'expense_loading': premium_with_expenses - pure_premium,\n",
    "        'profit_margin_amount': final_premium - premium_with_expenses,\n",
    "        'final_premium': final_premium\n",
    "    }\n",
    "\n",
    "# Example risk profiles\n",
    "risk_profiles = [\n",
    "    {\"name\": \"Very Low Risk\", \"p_claim\": 0.0005, \"severity\": 1000},\n",
    "    {\"name\": \"Low Risk\", \"p_claim\": 0.001, \"severity\": 2000},\n",
    "    {\"name\": \"Medium Risk\", \"p_claim\": 0.01, \"severity\": 5000},\n",
    "    {\"name\": \"High Risk\", \"p_claim\": 0.05, \"severity\": 15000},\n",
    "    {\"name\": \"Very High Risk\", \"p_claim\": 0.10, \"severity\": 30000}\n",
    "]\n",
    "\n",
    "print(\"RISK-BASED PREMIUM CALCULATION EXAMPLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for profile in risk_profiles:\n",
    "    premium = calculate_premium(profile['p_claim'], profile['severity'])\n",
    "    print(f\"\\n{profile['name']}:\")\n",
    "    print(f\"  ‚Ä¢ Claim Probability: {profile['p_claim']*100:.3f}%\")\n",
    "    print(f\"  ‚Ä¢ Expected Severity: ${profile['severity']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ Pure Premium: ${premium['pure_premium']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ + Expenses: ${premium['expense_loading']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ + Profit: ${premium['profit_margin_amount']:,.2f}\")\n",
    "    print(f\"  ‚Ä¢ FINAL PREMIUM: ${premium['final_premium']:,.2f}\")\n",
    "\n",
    "# %%\n",
    "# Visualize premium components\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Premium breakdown for medium risk\n",
    "medium_premium = calculate_premium(0.01, 5000)\n",
    "components = ['Pure Risk', 'Expenses (15%)', 'Profit (10%)']\n",
    "values = [\n",
    "    medium_premium['pure_premium'],\n",
    "    medium_premium['expense_loading'],\n",
    "    medium_premium['profit_margin_amount']\n",
    "]\n",
    "colors = ['lightblue', 'lightgreen', 'gold']\n",
    "\n",
    "wedges, texts, autotexts = axes[0].pie(\n",
    "    values, labels=components, colors=colors, autopct='%1.1f%%',\n",
    "    startangle=90, explode=(0.05, 0.05, 0.05)\n",
    ")\n",
    "axes[0].set_title('Premium Composition\\n(Medium Risk Policy)')\n",
    "\n",
    "# Premium comparison across risk levels\n",
    "risk_names = [p['name'] for p in risk_profiles]\n",
    "premiums = [calculate_premium(p['p_claim'], p['severity'])['final_premium'] for p in risk_profiles]\n",
    "\n",
    "bars = axes[1].bar(risk_names, premiums, color=['lightgreen', 'lightblue', 'gold', 'orange', 'salmon'], edgecolor='black')\n",
    "axes[1].set_ylabel('Annual Premium ($)')\n",
    "axes[1].set_title('Premium Comparison Across Risk Profiles')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, premium in zip(bars, premiums):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height * 1.02,\n",
    "                f'${premium:,.0f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / \"premium_calculations.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4565191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ### 7. Generate Comprehensive Report\n",
    "\n",
    "# %%\n",
    "# Create analysis report\n",
    "analysis_report = {\n",
    "    \"analysis_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"project_info\": {\n",
    "        \"project_root\": str(PROJECT_ROOT),\n",
    "        \"data_file\": str(DATA_PATH),\n",
    "        \"dataset_shape\": {\n",
    "            \"rows\": int(df.shape[0]),\n",
    "            \"columns\": int(df.shape[1])\n",
    "        },\n",
    "        \"total_policies\": int(len(df)),\n",
    "        \"policies_with_claims\": int((df['TotalClaims'] > 0).sum()) if 'TotalClaims' in df.columns else None,\n",
    "        \"high_claim_policies\": int(df['HighClaim'].sum()) if 'HighClaim' in df.columns else None\n",
    "    },\n",
    "    \"model_performance\": {\n",
    "        \"regression\": regression_performance,\n",
    "        \"classification\": classification_performance\n",
    "    },\n",
    "    \"best_models\": {\n",
    "        \"regression\": {\n",
    "            \"name\": \"Random Forest\",\n",
    "            \"r2\": regression_performance['rf']['r2'],\n",
    "            \"rmse\": regression_performance['rf']['rmse']\n",
    "        },\n",
    "        \"classification\": {\n",
    "            \"name\": \"Logistic Regression\",\n",
    "            \"auc\": classification_performance['logistic']['auc'],\n",
    "            \"accuracy\": classification_performance['logistic']['accuracy']\n",
    "        }\n",
    "    },\n",
    "    \"key_findings\": [\n",
    "        \"Random Forest performed best for claim severity prediction (R¬≤=0.6268)\",\n",
    "        \"All classification models showed excellent performance (AUC > 0.96)\",\n",
    "        \"Data leakage detected: StratifyBin was used in classification training\",\n",
    "        \"Logistic regression showed convergence warning (needs more iterations)\"\n",
    "    ],\n",
    "    \"critical_issues\": [\n",
    "        \"DATA LEAKAGE: StratifyBin must be removed from classification model training\",\n",
    "        \"SUSPICIOUS METRICS: Classification AUC > 0.99 suggests potential data leakage\",\n",
    "        \"CATBOOST FAILED: NaN handling issues in categorical features\"\n",
    "    ],\n",
    "    \"recommendations\": [\n",
    "        \"Retrain classification models without StratifyBin leakage feature\",\n",
    "        \"Use Random Forest for production claim severity prediction\",\n",
    "        \"Investigate potential data leakage in classification models\",\n",
    "        \"Fix NaN handling for CatBoost compatibility\",\n",
    "        \"Implement cross-validation for more robust performance estimates\"\n",
    "    ],\n",
    "    \"business_implications\": [\n",
    "        \"Risk-based pricing can be implemented using model predictions\",\n",
    "        \"High-risk profiles can be identified for targeted underwriting\",\n",
    "        \"Premium optimization opportunities exist through better risk assessment\",\n",
    "        \"Coverage amount validation is critical for claim severity management\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save report\n",
    "with open(REPORTS_DIR / \"modeling_analysis_report.json\", 'w') as f:\n",
    "    json.dump(convert_to_serializable(analysis_report), f, indent=2)\n",
    "\n",
    "# Also save a markdown version for easy reading\n",
    "md_report = f\"\"\"# Modeling Analysis Report\n",
    "\n",
    "**Date:** {analysis_report['analysis_date']}\n",
    "**Project:** {analysis_report['project_info']['project_root']}\n",
    "\n",
    "## Dataset Overview\n",
    "- Total policies: {analysis_report['project_info']['total_policies']:,}\n",
    "- Policies with claims: {analysis_report['project_info']['policies_with_claims']:,}\n",
    "- High claim policies: {analysis_report['project_info']['high_claim_policies']:,}\n",
    "\n",
    "## Best Performing Models\n",
    "\n",
    "### Regression (Claim Severity)\n",
    "**Model:** {analysis_report['best_models']['regression']['name']}\n",
    "- R¬≤ Score: {analysis_report['best_models']['regression']['r2']:.4f}\n",
    "- RMSE: {analysis_report['best_models']['regression']['rmse']:.4f}\n",
    "\n",
    "### Classification (Claim Probability)\n",
    "**Model:** {analysis_report['best_models']['classification']['name']}\n",
    "- AUC: {analysis_report['best_models']['classification']['auc']:.4f}\n",
    "- Accuracy: {analysis_report['best_models']['classification']['accuracy']:.4f}\n",
    "\n",
    "## ‚ö†Ô∏è CRITICAL ISSUES\n",
    "{chr(10).join(['- ' + issue for issue in analysis_report['critical_issues']])}\n",
    "\n",
    "## Key Findings\n",
    "{chr(10).join(['- ' + finding for finding in analysis_report['key_findings']])}\n",
    "\n",
    "## Recommendations\n",
    "{chr(10).join(['- ' + rec for rec in analysis_report['recommendations']])}\n",
    "\n",
    "## Business Implications\n",
    "{chr(10).join(['- ' + imp for imp in analysis_report['business_implications']])}\n",
    "\n",
    "## Next Steps Priority\n",
    "1. **IMMEDIATE**: Fix data leakage (remove StratifyBin) and retrain models\n",
    "2. **SHORT-TERM**: Validate classification model performance after leakage fix\n",
    "3. **MEDIUM-TERM**: Implement production monitoring for model drift\n",
    "4. **LONG-TERM**: Develop automated risk assessment dashboard\n",
    "\n",
    "## Files Generated\n",
    "All analysis files are available in: {REPORTS_DIR}\n",
    "\"\"\"\n",
    "\n",
    "md_report_path = REPORTS_DIR / \"modeling_analysis_report.md\"\n",
    "with open(md_report_path, 'w') as f:\n",
    "    f.write(md_report)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Key Insights:\")\n",
    "print(f\"1. Best regression model: Random Forest (R¬≤ = {regression_performance['rf']['r2']:.4f})\")\n",
    "print(f\"2. Best classification model: Logistic Regression (AUC = {classification_performance['logistic']['auc']:.4f})\")\n",
    "print(f\"3. Dataset: {len(df):,} policies, {(df['TotalClaims'] > 0).sum():,} with claims\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Critical Issues to Address:\")\n",
    "print(\"1. DATA LEAKAGE: StratifyBin in classification model\")\n",
    "print(\"2. Suspiciously high classification AUC (> 0.99)\")\n",
    "print(\"3. CatBoost compatibility issues\")\n",
    "\n",
    "print(f\"\\n‚úÖ Next Steps:\")\n",
    "print(\"1. Fix data leakage and retrain models\")\n",
    "print(\"2. Validate model performance after fixes\")\n",
    "print(\"3. Implement risk-based pricing model\")\n",
    "print(\"4. Monitor model performance in production\")\n",
    "\n",
    "print(f\"\\nüìÅ Reports saved in: {REPORTS_DIR}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
