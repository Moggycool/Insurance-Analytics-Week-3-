{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4907db76",
   "metadata": {},
   "source": [
    "# Insurance Analytics - Week 3 EDA Notebook\n",
    "- A Comprehensive Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c296c",
   "metadata": {},
   "source": [
    "1. INITIAL SETUP & IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4593e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insurance Analytics - Week 3 EDA Notebook\n",
    "# A Comprehensive Exploratory Data Analysis\n",
    "\"\"\"\n",
    "Insurance Analytics - Week 3 EDA Notebook\n",
    "Comprehensive Exploratory Data Analysis\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# 1. INITIAL SETUP & IMPORTS\n",
    "# ============================================================================\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "current_dir = os.getcwd()\n",
    "if os.path.basename(current_dir) == 'notebooks':\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "    os.chdir(project_root)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"üìÇ Project Root: {project_root}\")\n",
    "print(f\"üìÅ Working Directory: {os.getcwd()}\")\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visual styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (12, 6),\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12\n",
    "})\n",
    "\n",
    "# Import custom modules\n",
    "try:\n",
    "    from src.data_preprocessing import DataPreprocessor\n",
    "    from src.utils import DataUtils\n",
    "    from src.visualization import DataVisualizer\n",
    "    # Try to import eda, but handle if it has issues\n",
    "    try:\n",
    "        from src.eda import InsuranceEDA\n",
    "        eda_available = True\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ö†Ô∏è Could not import InsuranceEDA: {e}\")\n",
    "        print(\"Will use DataUtils and DataVisualizer directly\")\n",
    "        eda_available = False\n",
    "    print(\"‚úÖ Successfully imported custom modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Please ensure your src modules are accessible\")\n",
    "    eda_available = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 2. DATA LOADING & PREPROCESSING WITH TOTALCLAIMS FIX\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA LOADING & PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define paths\n",
    "RAW_DATA_PATH = \"D:/Python/Week-3/Raw_Data/MachineLearningRating_v3.txt\"\n",
    "PROCESSED_DATA_PATH = \"D:/Python/Week-3/Insurance-Analytics-Week-3-/data/processed/processed_MachineLearningRating_v3.csv\"\n",
    "CLAIMS_DATA_PATH = \"D:/Python/Week-3/Insurance-Analytics-Week-3-/data/processed/claims_positive_MachineLearningRating_v3.csv\"\n",
    "\n",
    "print(\"\\nüîç CHOOSE DATASET TO ANALYZE:\")\n",
    "print(\"1. Full dataset (all policies)\")\n",
    "print(\"2. Claims dataset (only policies with TotalClaims > 0)\")\n",
    "choice = input(\"\\nEnter choice (1 or 2): \").strip()\n",
    "\n",
    "if choice == \"2\":\n",
    "    USE_CLAIMS_ONLY = True\n",
    "    PROCESSED_DATA_PATH = CLAIMS_DATA_PATH\n",
    "    print(\"\\nüìä Will analyze CLAIMS DATA ONLY (TotalClaims > 0)\")\n",
    "else:\n",
    "    USE_CLAIMS_ONLY = False\n",
    "    print(\"\\nüìä Will analyze FULL DATASET (all policies)\")\n",
    "\n",
    "# Check if processed data exists\n",
    "if os.path.exists(PROCESSED_DATA_PATH):\n",
    "    print(f\"\\nüìÅ Loading processed data from: {PROCESSED_DATA_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(PROCESSED_DATA_PATH, sep='|')\n",
    "        print(f\"‚úÖ Loaded {len(df):,} rows, {len(df.columns)} columns\")\n",
    "        if USE_CLAIMS_ONLY:\n",
    "            print(\"üìà Analyzing ONLY policies with claims (TotalClaims > 0)\")\n",
    "        else:\n",
    "            print(\"üìà Analyzing ALL policies\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading processed data: {e}\")\n",
    "        print(\"üîß Falling back to preprocessing...\")\n",
    "        df = None\n",
    "else:\n",
    "    print(\"üîç Processed data not found. Starting preprocessing...\")\n",
    "    df = None\n",
    "\n",
    "# Preprocess if needed\n",
    "if df is None:\n",
    "    print(\"\\nüîÑ Initializing DataPreprocessor...\")\n",
    "    \n",
    "    if USE_CLAIMS_ONLY:\n",
    "        print(\"üîç Will filter for TotalClaims > 0 during processing\")\n",
    "        claims_filter = \"positive\"\n",
    "        out_path = CLAIMS_DATA_PATH\n",
    "    else:\n",
    "        claims_filter = None\n",
    "        out_path = PROCESSED_DATA_PATH\n",
    "    \n",
    "    dp = DataPreprocessor(\n",
    "        raw_path=RAW_DATA_PATH,\n",
    "        out_path=out_path,\n",
    "        chunksize=100_000,\n",
    "        delimiter=\"|\",\n",
    "        log_transform=True,\n",
    "        claims_filter=claims_filter\n",
    "    )\n",
    "    \n",
    "    print(\"üîß Processing data with enhanced features...\")\n",
    "    df = dp.process(\n",
    "        save_format=\"csv\",\n",
    "        create_features=True,\n",
    "        run_quality_checks=True\n",
    "    )\n",
    "    print(\"‚úÖ Preprocessing completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 3. FIX TOTALCLAIMS CONVERSION ISSUE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIXING TOTALCLAIMS CONVERSION ISSUE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check current TotalClaims values\n",
    "if 'TotalClaims' in df.columns:\n",
    "    print(f\"\\nüîç CURRENT TOTALCLAIMS STATUS:\")\n",
    "    print(f\"‚Ä¢ Data type: {df['TotalClaims'].dtype}\")\n",
    "    print(f\"‚Ä¢ Total policies: {len(df):,}\")\n",
    "    print(f\"‚Ä¢ Policies with claims > 0: {(df['TotalClaims'] > 0).sum():,}\")\n",
    "    print(f\"‚Ä¢ Total claims amount: ${df['TotalClaims'].sum():,.2f}\")\n",
    "    \n",
    "    # If all claims are zero but we expect some, fix the conversion\n",
    "    if (df['TotalClaims'] > 0).sum() == 0:\n",
    "        print(\"\\n‚ö†Ô∏è WARNING: All TotalClaims are zero!\")\n",
    "        print(\"üîß Fixing TotalClaims conversion from raw data...\")\n",
    "        \n",
    "        # Function to properly convert TotalClaims values\n",
    "        def fix_totalclaims_conversion():\n",
    "            \"\"\"Reload TotalClaims from raw data with proper conversion\"\"\"\n",
    "            claims_list = []\n",
    "            chunksize = 100000\n",
    "            rows_processed = 0\n",
    "            \n",
    "            print(f\"  Loading TotalClaims from raw data: {RAW_DATA_PATH}\")\n",
    "            \n",
    "            # Read raw data in chunks\n",
    "            for chunk in pd.read_csv(RAW_DATA_PATH, sep='|', \n",
    "                                    chunksize=chunksize,\n",
    "                                    usecols=['TotalClaims'],\n",
    "                                    dtype=str):\n",
    "                \n",
    "                # Convert each value properly\n",
    "                for val in chunk['TotalClaims']:\n",
    "                    if pd.isna(val) or val == '':\n",
    "                        claims_list.append(0.0)\n",
    "                    elif val == '.000000000000':\n",
    "                        claims_list.append(0.0)\n",
    "                    elif val.startswith('.') and val[1:].replace('0', '').replace('.', '') == '':\n",
    "                        # Handle cases like '.000000' or '.0'\n",
    "                        claims_list.append(0.0)\n",
    "                    else:\n",
    "                        try:\n",
    "                            # Remove any non-numeric characters except decimal point\n",
    "                            clean_val = ''.join(c for c in val if c.isdigit() or c == '.' or c == '-')\n",
    "                            if clean_val and clean_val != '.':\n",
    "                                claims_list.append(float(clean_val))\n",
    "                            else:\n",
    "                                claims_list.append(0.0)\n",
    "                        except:\n",
    "                            claims_list.append(0.0)\n",
    "                \n",
    "                rows_processed += len(chunk)\n",
    "                if rows_processed % 500000 == 0:\n",
    "                    print(f\"    Processed {rows_processed:,} rows...\")\n",
    "            \n",
    "            return claims_list\n",
    "        \n",
    "        # Get the properly converted claims\n",
    "        print(\"  Converting TotalClaims values...\")\n",
    "        fixed_claims = fix_totalclaims_conversion()\n",
    "        \n",
    "        # Ensure we have the right number of rows\n",
    "        if len(fixed_claims) != len(df):\n",
    "            print(f\"  ‚ö†Ô∏è Warning: Length mismatch. Raw has {len(fixed_claims)} rows, df has {len(df)} rows\")\n",
    "            # Truncate or pad as needed\n",
    "            if len(fixed_claims) > len(df):\n",
    "                fixed_claims = fixed_claims[:len(df)]\n",
    "            else:\n",
    "                fixed_claims.extend([0.0] * (len(df) - len(fixed_claims)))\n",
    "        \n",
    "        # Replace the column\n",
    "        df['TotalClaims_Original'] = df['TotalClaims']  # Keep original for comparison\n",
    "        df['TotalClaims'] = fixed_claims\n",
    "        \n",
    "        print(f\"\\n‚úÖ TOTALCLAIMS AFTER FIX:\")\n",
    "        print(f\"‚Ä¢ Data type: {df['TotalClaims'].dtype}\")\n",
    "        print(f\"‚Ä¢ Policies with claims > 0: {(df['TotalClaims'] > 0).sum():,} ({(df['TotalClaims'] > 0).sum()/len(df)*100:.2f}%)\")\n",
    "        print(f\"‚Ä¢ Total claims amount: ${df['TotalClaims'].sum():,.2f}\")\n",
    "        \n",
    "        if (df['TotalClaims'] > 0).sum() > 0:\n",
    "            claims_data = df[df['TotalClaims'] > 0]['TotalClaims']\n",
    "            print(f\"‚Ä¢ Average claim amount: ${claims_data.mean():,.2f}\")\n",
    "            print(f\"‚Ä¢ Median claim amount: ${claims_data.median():,.2f}\")\n",
    "            print(f\"‚Ä¢ Max claim amount: ${claims_data.max():,.2f}\")\n",
    "            print(f\"‚Ä¢ Min claim amount (>0): ${claims_data.min():,.2f}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ TotalClaims already has positive values!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è TotalClaims column not found in dataset\")\n",
    "\n",
    "# Quick check of dataset\n",
    "print(f\"\\nüìä Dataset shape: {df.shape}\")\n",
    "print(f\"üß† Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 4. UPDATE DERIVED COLUMNS AFTER FIX\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UPDATING DERIVED COLUMNS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Recalculate LossRatio if needed\n",
    "if 'TotalClaims' in df.columns and 'TotalPremium' in df.columns:\n",
    "    print(\"\\nüîÑ Recalculating LossRatio...\")\n",
    "    \n",
    "    # Calculate LossRatio\n",
    "    df['LossRatio'] = df['TotalClaims'] / df['TotalPremium'].replace(0, np.nan)\n",
    "    df['LossRatio'] = df['LossRatio'].clip(lower=0, upper=10)  # Cap at 1000%\n",
    "    \n",
    "    # Calculate claim indicators\n",
    "    df['HasClaim'] = (df['TotalClaims'] > 0).astype('int8')\n",
    "    \n",
    "    print(f\"‚úÖ Derived columns updated:\")\n",
    "    print(f\"‚Ä¢ Average Loss Ratio: {df['LossRatio'].mean():.2%}\")\n",
    "    print(f\"‚Ä¢ Claim Frequency: {df['HasClaim'].mean():.2%}\")\n",
    "    \n",
    "    if (df['TotalClaims'] > 0).sum() > 0:\n",
    "        print(f\"‚Ä¢ Average Loss Ratio (claims only): {df[df['TotalClaims'] > 0]['LossRatio'].mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 4. EDA IMPLEMENTATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUBRIC 1: EDA IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize utility objects\n",
    "utils = DataUtils()\n",
    "viz = DataVisualizer()\n",
    "\n",
    "# Initialize EDA if available\n",
    "if eda_available:\n",
    "    eda = InsuranceEDA(df)\n",
    "    print(\"‚úÖ Using InsuranceEDA class for analysis\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Using direct methods for analysis (InsuranceEDA not available)\")\n",
    "    eda = None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.1 DATA SUMMARIZATION (Rubric 1.1)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüìã 1.1 DATA SUMMARIZATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Data structure summary using DataUtils\n",
    "print(\"üìä DATA STRUCTURE SUMMARY\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚Ä¢ Rows: {df.shape[0]:,}\")\n",
    "print(f\"‚Ä¢ Columns: {df.shape[1]}\")\n",
    "print(f\"‚Ä¢ Memory: {utils.memory_usage(df):.2f} MB\")\n",
    "\n",
    "if USE_CLAIMS_ONLY:\n",
    "    print(f\"‚Ä¢ Dataset Type: Claims Data Only (TotalClaims > 0)\")\n",
    "\n",
    "print(\"\\nüìä DATA TYPES:\")\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"  ‚Ä¢ {dtype}: {count} columns\")\n",
    "\n",
    "# Enhanced descriptive statistics\n",
    "print(\"\\nüìà ENHANCED DESCRIPTIVE STATISTICS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Key numerical features for insurance analysis\n",
    "key_numerical = ['TotalPremium', 'TotalClaims', 'SumInsured', \n",
    "                 'CalculatedPremiumPerTerm', 'LossRatio', 'VehicleAge',\n",
    "                 'PremiumRate', 'HasClaim']\n",
    "\n",
    "existing_numerical = [col for col in key_numerical if col in df.columns]\n",
    "if existing_numerical:\n",
    "    desc_stats = df[existing_numerical].describe().T.round(2)\n",
    "    \n",
    "    # Add additional statistics\n",
    "    desc_stats['skewness'] = df[existing_numerical].skew().round(3)\n",
    "    desc_stats['kurtosis'] = df[existing_numerical].kurtosis().round(3)\n",
    "    desc_stats['zeros'] = (df[existing_numerical] == 0).sum()\n",
    "    desc_stats['zeros_pct'] = ((df[existing_numerical] == 0).sum() / len(df) * 100).round(2)\n",
    "    \n",
    "    print(\"\\nDescriptive Statistics for Key Insurance Features:\")\n",
    "    print(desc_stats)\n",
    "    \n",
    "    # Save to file for documentation\n",
    "    os.makedirs('reports', exist_ok=True)\n",
    "    desc_stats.to_csv('reports/descriptive_statistics.csv')\n",
    "    print(\"üíæ Saved descriptive statistics to 'reports/descriptive_statistics.csv'\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.2 DATA QUALITY ASSESSMENT (Rubric 1.2)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüîç 1.2 DATA QUALITY ASSESSMENT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Missing value analysis\n",
    "print(\"‚ùì MISSING VALUES ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "missing = df.isna().sum()\n",
    "missing_pct = missing / len(df) * 100\n",
    "missing_df = pd.DataFrame({\"Missing\": missing, \"Percent\": missing_pct})\n",
    "missing_df = missing_df[missing_df[\"Missing\"] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_df.sort_values(\"Percent\", ascending=False).head(10))\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "\n",
    "# Enhanced quality report\n",
    "print(\"\\nüìã ENHANCED DATA QUALITY REPORT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"‚Ä¢ Duplicate rows: {duplicate_count:,} ({duplicate_count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Check for invalid values in key columns\n",
    "print(\"\\nüîé INVALID VALUES CHECK:\")\n",
    "key_columns = {\n",
    "    'TotalPremium': (df['TotalPremium'] < 0).sum() if 'TotalPremium' in df.columns else 0,\n",
    "    'TotalClaims': (df['TotalClaims'] < 0).sum() if 'TotalClaims' in df.columns else 0,\n",
    "    'LossRatio': ((df['LossRatio'] < 0) | (df['LossRatio'] > 10)).sum() if 'LossRatio' in df.columns else 0\n",
    "}\n",
    "\n",
    "for col, count in key_columns.items():\n",
    "    if count > 0:\n",
    "        print(f\"  [WARNING] {col}: {count:,} invalid values\")\n",
    "    else:\n",
    "        print(f\"  [OK] {col}: No invalid values\")\n",
    "\n",
    "# Special check for claims data\n",
    "if USE_CLAIMS_ONLY and 'TotalClaims' in df.columns:\n",
    "    print(\"\\nüîç CLAIMS DATA SPECIFIC CHECK:\")\n",
    "    zero_claims = (df['TotalClaims'] == 0).sum()\n",
    "    if zero_claims > 0:\n",
    "        print(f\"  [WARNING] Found {zero_claims} rows with TotalClaims = 0 in claims-only dataset\")\n",
    "    else:\n",
    "        print(f\"  [OK] All rows have TotalClaims > 0\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.3 UNIVARIATE ANALYSIS (Rubric 1.3)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüìä 1.3 UNIVARIATE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Get numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"‚Ä¢ Numerical columns to analyze: {len(numerical_cols)}\")\n",
    "print(f\"‚Ä¢ Categorical columns to analyze: {len(categorical_cols)}\")\n",
    "\n",
    "# Select top features for visualization\n",
    "top_numerical = numerical_cols[:6] if len(numerical_cols) > 6 else numerical_cols\n",
    "print(f\"\\nüìà HISTOGRAMS FOR: {', '.join(top_numerical)}\")\n",
    "\n",
    "# Create histograms in a grid\n",
    "if len(top_numerical) > 0:\n",
    "    n_cols = min(3, len(top_numerical))\n",
    "    n_rows = (len(top_numerical) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(top_numerical):\n",
    "        ax = axes[idx]\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            ax.hist(data, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "            ax.set_title(f'Distribution of {col}', fontsize=11)\n",
    "            ax.set_xlabel(col, fontsize=9)\n",
    "            ax.set_ylabel('Frequency', fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            stats_text = f\"Mean: {data.mean():.2f}\\nStd: {data.std():.2f}\"\n",
    "            if USE_CLAIMS_ONLY and col == 'TotalClaims':\n",
    "                stats_text += f\"\\nClaims Only\"\n",
    "            ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,\n",
    "                   fontsize=8, verticalalignment='top', horizontalalignment='right',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(top_numerical), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    title = 'Univariate Analysis: Numerical Feature Distributions'\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        title += ' (Claims Data Only)'\n",
    "    plt.suptitle(title, fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Bar charts for categorical features\n",
    "top_categorical = categorical_cols[:4] if len(categorical_cols) > 4 else categorical_cols\n",
    "print(f\"\\nüìä BAR CHARTS FOR: {', '.join(top_categorical)}\")\n",
    "\n",
    "for col in top_categorical:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    value_counts = df[col].value_counts().head(15)  # Top 15 categories\n",
    "    value_counts.plot(kind='bar', color='lightcoral', edgecolor='black')\n",
    "    title = f'Distribution of {col} (Top 15)'\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        title += ' (Claims Data)'\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (idx, val) in enumerate(value_counts.items()):\n",
    "        plt.text(i, val + max(value_counts)*0.01, f'{val:,}', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.4 BIVARIATE/MULTIVARIATE ANALYSIS (Rubric 1.4)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüîó 1.4 BIVARIATE/MULTIVARIATE ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 1.4.1 Correlation Analysis (REQUIRED)\n",
    "print(\"\\nüìä CORRELATION MATRIX ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Select key numerical features for correlation\n",
    "correlation_features = ['TotalPremium', 'TotalClaims', 'SumInsured', \n",
    "                       'CalculatedPremiumPerTerm', 'VehicleAge', 'LossRatio',\n",
    "                       'PremiumRate']\n",
    "\n",
    "available_features = [col for col in correlation_features if col in df.columns]\n",
    "\n",
    "if len(available_features) >= 3:\n",
    "    print(f\"Calculating correlations for: {', '.join(available_features)}\")\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df[available_features].corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "    title = 'Correlation Matrix of Key Insurance Features'\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        title += ' (Claims Data Only)'\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí™ STRONGEST CORRELATIONS (|r| > 0.5)\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Find strong correlations\n",
    "    strong_correlations = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_value = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.5:\n",
    "                strong_correlations.append((\n",
    "                    corr_matrix.columns[i],\n",
    "                    corr_matrix.columns[j],\n",
    "                    corr_value\n",
    "                ))\n",
    "    \n",
    "    if strong_correlations:\n",
    "        for col1, col2, corr_val in sorted(strong_correlations, key=lambda x: abs(x[2]), reverse=True):\n",
    "            direction = \"positive\" if corr_val > 0 else \"negative\"\n",
    "            print(f\"‚Ä¢ {col1} ‚Üî {col2}: {corr_val:.3f} ({direction})\")\n",
    "    else:\n",
    "        print(\"No strong correlations (|r| > 0.5) found among selected features\")\n",
    "    \n",
    "    # Save correlation matrix\n",
    "    corr_matrix.to_csv('reports/correlation_matrix.csv')\n",
    "    print(\"üíæ Saved correlation matrix to 'reports/correlation_matrix.csv'\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Need at least 3 numerical features for correlation matrix. Found: {len(available_features)}\")\n",
    "\n",
    "# 1.4.2 Enhanced Scatter Plots with Fixes\n",
    "print(\"\\nüìç ENHANCED SCATTER PLOTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create scatter plots for important relationships\n",
    "scatter_pairs = [\n",
    "    ('TotalPremium', 'TotalClaims'),\n",
    "    ('SumInsured', 'CalculatedPremiumPerTerm'),\n",
    "    ('VehicleAge', 'LossRatio')\n",
    "]\n",
    "\n",
    "for x_col, y_col in scatter_pairs:\n",
    "    if x_col in df.columns and y_col in df.columns:\n",
    "        print(f\"\\nScatter plot: {x_col} vs {y_col}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Filter out NaN values\n",
    "        valid_data = df[[x_col, y_col]].dropna()\n",
    "        \n",
    "        if len(valid_data) > 10:  # Need enough data points\n",
    "            print(f\"‚Ä¢ Data points: {len(valid_data):,}\")\n",
    "            print(f\"‚Ä¢ {x_col} range: [{valid_data[x_col].min():.2f}, {valid_data[x_col].max():.2f}]\")\n",
    "            print(f\"‚Ä¢ {y_col} range: [{valid_data[y_col].min():.2f}, {valid_data[y_col].max():.2f}]\")\n",
    "            \n",
    "            # Check if data needs scaling\n",
    "            if valid_data[y_col].max() - valid_data[y_col].min() < 0.1:\n",
    "                print(f\"‚ö†Ô∏è Warning: {y_col} has very small range. Checking scaling...\")\n",
    "                \n",
    "                # Try to identify if values are in thousands/millions\n",
    "                mean_val = valid_data[y_col].mean()\n",
    "                if abs(mean_val) < 1:\n",
    "                    print(f\"  ‚Ä¢ Values appear to be in decimal format\")\n",
    "                    print(f\"  ‚Ä¢ Consider if values need to be multiplied (e.g., by 1000)\")\n",
    "            \n",
    "            # Calculate correlation\n",
    "            correlation = valid_data[x_col].corr(valid_data[y_col])\n",
    "            print(f\"‚Ä¢ Correlation: {correlation:.4f}\")\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Create scatter plot with better visualization\n",
    "            if len(valid_data) > 1000:\n",
    "                # Use hexbin for large datasets\n",
    "                plt.hexbin(valid_data[x_col], valid_data[y_col], \n",
    "                          gridsize=50, cmap='Blues', mincnt=1)\n",
    "                plt.colorbar(label='Count')\n",
    "            else:\n",
    "                # Regular scatter for smaller datasets\n",
    "                plt.scatter(valid_data[x_col], valid_data[y_col], \n",
    "                          alpha=0.5, s=20, color='steelblue', edgecolor='black')\n",
    "            \n",
    "            # Add trend line if we have valid correlation\n",
    "            if abs(correlation) > 0.1:  # Only add if there's some correlation\n",
    "                try:\n",
    "                    z = np.polyfit(valid_data[x_col], valid_data[y_col], 1)\n",
    "                    p = np.poly1d(z)\n",
    "                    \n",
    "                    # Generate x values for trend line\n",
    "                    x_vals = np.linspace(valid_data[x_col].min(), \n",
    "                                        valid_data[x_col].max(), 100)\n",
    "                    plt.plot(x_vals, p(x_vals), \"r--\", alpha=0.8, \n",
    "                            label=f'Trend: y = {z[0]:.6f}x + {z[1]:.4f}')\n",
    "                    plt.legend()\n",
    "                except:\n",
    "                    print(\"  ‚ö†Ô∏è Could not calculate trend line\")\n",
    "            \n",
    "            title = f'{x_col} vs {y_col}'\n",
    "            if USE_CLAIMS_ONLY:\n",
    "                title += ' (Claims Data)'\n",
    "            plt.title(title, fontsize=14)\n",
    "            plt.xlabel(x_col, fontsize=12)\n",
    "            plt.ylabel(y_col, fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics box\n",
    "            stats_text = (f'Correlation: {correlation:.4f}\\n'\n",
    "                         f'Data points: {len(valid_data):,}\\n'\n",
    "                         f'Mean {x_col}: {valid_data[x_col].mean():.2f}\\n'\n",
    "                         f'Mean {y_col}: {valid_data[y_col].mean():.2f}')\n",
    "            \n",
    "            plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, \n",
    "                    fontsize=10, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Also create a log-scale version if data spans large ranges\n",
    "            if (valid_data[x_col].max() / valid_data[x_col].min() > 100 or \n",
    "                valid_data[y_col].max() / valid_data[y_col].min() > 100):\n",
    "                \n",
    "                print(f\"üìà Creating log-scale version for better visualization\")\n",
    "                \n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.scatter(valid_data[x_col], valid_data[y_col], \n",
    "                          alpha=0.5, s=20, color='steelblue', edgecolor='black')\n",
    "                \n",
    "                plt.xscale('log')\n",
    "                plt.yscale('log')\n",
    "                plt.title(f'{x_col} vs {y_col} (Log Scale)', fontsize=14)\n",
    "                plt.xlabel(f'{x_col} (log scale)', fontsize=12)\n",
    "                plt.ylabel(f'{y_col} (log scale)', fontsize=12)\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Insufficient data for scatter plot: only {len(valid_data)} valid points\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cannot plot {x_col} vs {y_col}: columns not found\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.5 OUTLIER DETECTION (Rubric 1.5)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüö® 1.5 OUTLIER DETECTION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nüì¶ ENHANCED OUTLIER DETECTION WITH BOX PLOTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Focus on key insurance columns\n",
    "key_outlier_cols = ['TotalPremium', 'TotalClaims', 'SumInsured', \n",
    "                   'CalculatedPremiumPerTerm', 'LossRatio', 'VehicleAge']\n",
    "\n",
    "available_outlier_cols = [col for col in key_outlier_cols if col in df.columns]\n",
    "\n",
    "if available_outlier_cols:\n",
    "    print(f\"Generating box plots for: {', '.join(available_outlier_cols)}\")\n",
    "    \n",
    "    # Create subplots\n",
    "    n_cols = len(available_outlier_cols)\n",
    "    n_rows = (n_cols + 2) // 3  # Max 3 per row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    outlier_report = {}\n",
    "    \n",
    "    for idx, col in enumerate(available_outlier_cols):\n",
    "        ax = axes[idx]\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            # Calculate IQR and outliers\n",
    "            Q1 = data.quantile(0.25)\n",
    "            Q3 = data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = ((data < lower_bound) | (data > upper_bound)).sum()\n",
    "            outlier_pct = (outliers / len(data) * 100) if len(data) > 0 else 0\n",
    "            \n",
    "            outlier_report[col] = {\n",
    "                'outliers': int(outliers),\n",
    "                'outlier_pct': round(outlier_pct, 2),\n",
    "                'Q1': round(Q1, 2),\n",
    "                'Q3': round(Q3, 2),\n",
    "                'IQR': round(IQR, 2)\n",
    "            }\n",
    "            \n",
    "            # Create box plot\n",
    "            box = ax.boxplot(data, vert=True, patch_artist=True,\n",
    "                            boxprops=dict(facecolor='lightblue', color='darkblue'),\n",
    "                            medianprops=dict(color='red', linewidth=2),\n",
    "                            whiskerprops=dict(color='darkblue'),\n",
    "                            capprops=dict(color='darkblue'),\n",
    "                            flierprops=dict(marker='o', color='red', alpha=0.5, markersize=4))\n",
    "            \n",
    "            title = f'{col}\\nOutliers: {outliers} ({outlier_pct:.1f}%)'\n",
    "            ax.set_title(title, fontsize=11)\n",
    "            ax.set_ylabel('Value', fontsize=9)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'No Data', ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(col, fontsize=11)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(available_outlier_cols), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    title = 'Outlier Detection with Box Plots (IQR Method)'\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        title += ' (Claims Data)'\n",
    "    plt.suptitle(title, fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print outlier summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OUTLIER DETECTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    for col, stats in outlier_report.items():\n",
    "        if stats['outliers'] > 0:\n",
    "            print(f\"‚Ä¢ {col}: {stats['outliers']:,} outliers ({stats['outlier_pct']}%)\")\n",
    "        else:\n",
    "            print(f\"‚Ä¢ {col}: No outliers detected\")\n",
    "    \n",
    "    # Save outlier report\n",
    "    with open('reports/outlier_report.json', 'w') as f:\n",
    "        json.dump(outlier_report, f, indent=2)\n",
    "    print(\"üíæ Saved outlier report to 'reports/outlier_report.json'\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No key columns available for outlier detection\")\n",
    "\n",
    "# Continue with the rest of your notebook...\n",
    "# [Rest of your notebook code remains the same from section 4 onward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTIC CHECK FOR CLAIMS DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSTIC CHECK FOR CLAIMS DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check TotalClaims values\n",
    "if 'TotalClaims' in df.columns:\n",
    "    print(\"\\nüîç CHECKING TOTALCLAIMS VALUES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check data type\n",
    "    print(f\"‚Ä¢ Data type: {df['TotalClaims'].dtype}\")\n",
    "    \n",
    "    # Check basic statistics\n",
    "    claims_stats = df['TotalClaims'].describe()\n",
    "    print(f\"‚Ä¢ Min: {claims_stats['min']:.2f}\")\n",
    "    print(f\"‚Ä¢ Max: {claims_stats['max']:.2f}\")\n",
    "    print(f\"‚Ä¢ Mean: {claims_stats['mean']:.2f}\")\n",
    "    print(f\"‚Ä¢ Std: {claims_stats['std']:.2f}\")\n",
    "    \n",
    "    # Check if claims > 0\n",
    "    claims_positive = (df['TotalClaims'] > 0).sum()\n",
    "    claims_zero = (df['TotalClaims'] == 0).sum()\n",
    "    claims_negative = (df['TotalClaims'] < 0).sum()\n",
    "    \n",
    "    print(f\"\\nüìä CLAIMS DISTRIBUTION:\")\n",
    "    print(f\"‚Ä¢ Claims > 0: {claims_positive:,} rows ({claims_positive/len(df)*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Claims = 0: {claims_zero:,} rows ({claims_zero/len(df)*100:.1f}%)\")\n",
    "    print(f\"‚Ä¢ Claims < 0: {claims_negative:,} rows ({claims_negative/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample of actual claim values\n",
    "    print(f\"\\nüìã SAMPLE OF TOTALCLAIMS VALUES:\")\n",
    "    sample_claims = df['TotalClaims'].head(20)\n",
    "    for i, val in enumerate(sample_claims):\n",
    "        print(f\"  Row {i+1}: {val}\")\n",
    "    \n",
    "    # Check correlation with TotalPremium\n",
    "    if 'TotalPremium' in df.columns:\n",
    "        correlation = df['TotalPremium'].corr(df['TotalClaims'])\n",
    "        print(f\"\\nüìà CORRELATION WITH TOTALPREMIUM: {correlation:.4f}\")\n",
    "\n",
    "# Check TotalPremium values\n",
    "if 'TotalPremium' in df.columns:\n",
    "    print(\"\\nüîç CHECKING TOTALPREMIUM VALUES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check basic statistics\n",
    "    premium_stats = df['TotalPremium'].describe()\n",
    "    print(f\"‚Ä¢ Min: ${premium_stats['min']:.2f}\")\n",
    "    print(f\"‚Ä¢ Max: ${premium_stats['max']:.2f}\")\n",
    "    print(f\"‚Ä¢ Mean: ${premium_stats['mean']:.2f}\")\n",
    "    print(f\"‚Ä¢ Std: ${premium_stats['std']:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4.2 Enhanced Scatter Plots with Fixes\n",
    "print(\"\\nüìç ENHANCED SCATTER PLOTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create scatter plots for important relationships\n",
    "scatter_pairs = [\n",
    "    ('TotalPremium', 'TotalClaims'),\n",
    "    ('SumInsured', 'CalculatedPremiumPerTerm'),\n",
    "    ('VehicleAge', 'LossRatio')\n",
    "]\n",
    "\n",
    "for x_col, y_col in scatter_pairs:\n",
    "    if x_col in df.columns and y_col in df.columns:\n",
    "        print(f\"\\nScatter plot: {x_col} vs {y_col}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Filter out NaN values\n",
    "        valid_data = df[[x_col, y_col]].dropna()\n",
    "        \n",
    "        if len(valid_data) > 10:  # Need enough data points\n",
    "            print(f\"‚Ä¢ Data points: {len(valid_data):,}\")\n",
    "            print(f\"‚Ä¢ {x_col} range: [{valid_data[x_col].min():.2f}, {valid_data[x_col].max():.2f}]\")\n",
    "            print(f\"‚Ä¢ {y_col} range: [{valid_data[y_col].min():.2f}, {valid_data[y_col].max():.2f}]\")\n",
    "            \n",
    "            # Check if data needs scaling\n",
    "            if valid_data[y_col].max() - valid_data[y_col].min() < 0.1:\n",
    "                print(f\"‚ö†Ô∏è Warning: {y_col} has very small range. Checking scaling...\")\n",
    "                \n",
    "                # Try to identify if values are in thousands/millions\n",
    "                mean_val = valid_data[y_col].mean()\n",
    "                if abs(mean_val) < 1:\n",
    "                    print(f\"  ‚Ä¢ Values appear to be in decimal format\")\n",
    "                    print(f\"  ‚Ä¢ Consider if values need to be multiplied (e.g., by 1000)\")\n",
    "            \n",
    "            # Calculate correlation\n",
    "            correlation = valid_data[x_col].corr(valid_data[y_col])\n",
    "            print(f\"‚Ä¢ Correlation: {correlation:.4f}\")\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Create scatter plot with better visualization\n",
    "            if len(valid_data) > 1000:\n",
    "                # Use hexbin for large datasets\n",
    "                plt.hexbin(valid_data[x_col], valid_data[y_col], \n",
    "                          gridsize=50, cmap='Blues', mincnt=1)\n",
    "                plt.colorbar(label='Count')\n",
    "            else:\n",
    "                # Regular scatter for smaller datasets\n",
    "                plt.scatter(valid_data[x_col], valid_data[y_col], \n",
    "                          alpha=0.5, s=20, color='steelblue', edgecolor='black')\n",
    "            \n",
    "            # Add trend line if we have valid correlation\n",
    "            if abs(correlation) > 0.1:  # Only add if there's some correlation\n",
    "                try:\n",
    "                    z = np.polyfit(valid_data[x_col], valid_data[y_col], 1)\n",
    "                    p = np.poly1d(z)\n",
    "                    \n",
    "                    # Generate x values for trend line\n",
    "                    x_vals = np.linspace(valid_data[x_col].min(), \n",
    "                                        valid_data[x_col].max(), 100)\n",
    "                    plt.plot(x_vals, p(x_vals), \"r--\", alpha=0.8, \n",
    "                            label=f'Trend: y = {z[0]:.6f}x + {z[1]:.4f}')\n",
    "                    plt.legend()\n",
    "                except:\n",
    "                    print(\"  ‚ö†Ô∏è Could not calculate trend line\")\n",
    "            \n",
    "            title = f'{x_col} vs {y_col}'\n",
    "            if USE_CLAIMS_ONLY:\n",
    "                title += ' (Claims Data)'\n",
    "            plt.title(title, fontsize=14)\n",
    "            plt.xlabel(x_col, fontsize=12)\n",
    "            plt.ylabel(y_col, fontsize=12)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics box\n",
    "            stats_text = (f'Correlation: {correlation:.4f}\\n'\n",
    "                         f'Data points: {len(valid_data):,}\\n'\n",
    "                         f'Mean {x_col}: {valid_data[x_col].mean():.2f}\\n'\n",
    "                         f'Mean {y_col}: {valid_data[y_col].mean():.2f}')\n",
    "            \n",
    "            plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, \n",
    "                    fontsize=10, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Also create a log-scale version if data spans large ranges\n",
    "            if (valid_data[x_col].max() / valid_data[x_col].min() > 100 or \n",
    "                valid_data[y_col].max() / valid_data[y_col].min() > 100):\n",
    "                \n",
    "                print(f\"üìà Creating log-scale version for better visualization\")\n",
    "                \n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.scatter(valid_data[x_col], valid_data[y_col], \n",
    "                          alpha=0.5, s=20, color='steelblue', edgecolor='black')\n",
    "                \n",
    "                plt.xscale('log')\n",
    "                plt.yscale('log')\n",
    "                plt.title(f'{x_col} vs {y_col} (Log Scale)', fontsize=14)\n",
    "                plt.xlabel(f'{x_col} (log scale)', fontsize=12)\n",
    "                plt.ylabel(f'{y_col} (log scale)', fontsize=12)\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Insufficient data for scatter plot: only {len(valid_data)} valid points\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cannot plot {x_col} vs {y_col}: columns not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rubric_status[\"1.5 Outlier Detection\"] = \"Complete\"\n",
    "\n",
    "# ============================================================================\n",
    "# 4. ADDITIONAL ANALYSES & INSIGHTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADDITIONAL ANALYSES & INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Time Series Analysis\n",
    "if 'TransactionMonth' in df.columns:\n",
    "    print(\"\\nüìÖ TIME SERIES ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Convert to datetime if needed\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['TransactionMonth']):\n",
    "            df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "        \n",
    "        # Monthly aggregation\n",
    "        monthly_data = df.groupby(df['TransactionMonth'].dt.to_period('M')).agg({\n",
    "            'TotalPremium': 'sum',\n",
    "            'TotalClaims': 'sum',\n",
    "            'PolicyID': 'count'\n",
    "        }).rename(columns={'PolicyID': 'PolicyCount'})\n",
    "        \n",
    "        monthly_data['LossRatio'] = monthly_data['TotalClaims'] / monthly_data['TotalPremium']\n",
    "        \n",
    "        # Plot time series\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        monthly_data['TotalPremium'].plot(ax=axes[0,0], color='blue', marker='o', linewidth=2)\n",
    "        axes[0,0].set_title('Monthly Total Premium', fontsize=13)\n",
    "        axes[0,0].set_ylabel('Premium ($)', fontsize=11)\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        monthly_data['TotalClaims'].plot(ax=axes[0,1], color='red', marker='o', linewidth=2)\n",
    "        axes[0,1].set_title('Monthly Total Claims', fontsize=13)\n",
    "        axes[0,1].set_ylabel('Claims ($)', fontsize=11)\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        monthly_data['PolicyCount'].plot(ax=axes[1,0], color='green', marker='o', linewidth=2)\n",
    "        axes[1,0].set_title('Monthly Policy Count', fontsize=13)\n",
    "        axes[1,0].set_ylabel('Number of Policies', fontsize=11)\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        monthly_data['LossRatio'].plot(ax=axes[1,1], color='purple', marker='o', linewidth=2)\n",
    "        axes[1,1].set_title('Monthly Loss Ratio', fontsize=13)\n",
    "        axes[1,1].set_ylabel('Loss Ratio', fontsize=11)\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        title = 'Monthly Insurance Metrics Over Time'\n",
    "        if USE_CLAIMS_ONLY:\n",
    "            title += ' (Claims Data)'\n",
    "        plt.suptitle(title, fontsize=16, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not perform time series analysis: {e}\")\n",
    "\n",
    "# Categorical Analysis\n",
    "if 'CoverType' in df.columns:\n",
    "    print(\"\\nüõ°Ô∏è COVER TYPE ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    cover_stats = df.groupby('CoverType').agg({\n",
    "        'TotalPremium': ['count', 'sum', 'mean', 'std'],\n",
    "        'TotalClaims': ['sum', 'mean'],\n",
    "        'LossRatio': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"Cover Type Statistics (first 10):\")\n",
    "    print(cover_stats.head(10))\n",
    "    \n",
    "    # Visualize top cover types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_covers = df['CoverType'].value_counts().head(10)\n",
    "    top_covers.plot(kind='bar', color='lightseagreen')\n",
    "    title = 'Top 10 Cover Types by Policy Count'\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        title += ' (Claims Data)'\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('Cover Type', fontsize=12)\n",
    "    plt.ylabel('Number of Policies', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f810e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 5. SAVE RESULTS & GENERATE REPORT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING RESULTS & GENERATING REPORTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create reports directory\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "\n",
    "# Save dataset sample\n",
    "df_sample = df.head(1000)\n",
    "df_sample.to_csv('reports/data_sample.csv', index=False)\n",
    "print(\"Saved data sample to 'reports/data_sample.csv'\")\n",
    "\n",
    "# Generate summary report (using UTF-8 encoding to avoid Unicode errors)\n",
    "with open('reports/eda_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"EDA SUMMARY REPORT\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Dataset: {df.shape[0]} rows √ó {df.shape[1]} columns\\n\")\n",
    "    f.write(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\\n\")\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        f.write(\"Dataset Type: Claims Data Only (TotalClaims > 0)\\n\")\n",
    "    else:\n",
    "        f.write(\"Dataset Type: Full Dataset (All Policies)\\n\")\n",
    "    \n",
    "    f.write(\"\\nKEY FINDINGS:\\n\")\n",
    "    if 'LossRatio' in df.columns:\n",
    "        f.write(f\"- Average Loss Ratio: {df['LossRatio'].mean():.2%}\\n\")\n",
    "    if 'TotalClaims' in df.columns:\n",
    "        if USE_CLAIMS_ONLY:\n",
    "            f.write(f\"- Total Claims (in dataset): ${df['TotalClaims'].sum():,.2f}\\n\")\n",
    "            f.write(f\"- Average Claim Amount: ${df['TotalClaims'].mean():,.2f}\\n\")\n",
    "        else:\n",
    "            claim_freq = (df['TotalClaims'] > 0).mean()\n",
    "            f.write(f\"- Claim Frequency: {claim_freq:.2%}\\n\")\n",
    "            f.write(f\"- Total Claims: ${df['TotalClaims'].sum():,.2f}\\n\")\n",
    "    if 'TotalPremium' in df.columns:\n",
    "        f.write(f\"- Total Premium: ${df['TotalPremium'].sum():,.2f}\\n\")\n",
    "    if 'SumInsured' in df.columns:\n",
    "        f.write(f\"- Total Sum Insured: ${df['SumInsured'].sum():,.2f}\\n\")\n",
    "\n",
    "print(\"Generated summary report at 'reports/eda_summary.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 6. FINAL OUTPUT & NEXT STEPS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EDA COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nWHAT WAS ACCOMPLISHED:\")\n",
    "print(\"1. [OK] Data loading and preprocessing with DataPreprocessor\")\n",
    "print(\"2. [OK] Comprehensive descriptive statistics\")\n",
    "print(\"3. [OK] Data quality assessment with missing value analysis\")\n",
    "print(\"4. [OK] Univariate analysis with histograms and bar charts\")\n",
    "print(\"5. [OK] Bivariate analysis with correlation matrix and scatter plots\")\n",
    "print(\"6. [OK] Outlier detection with box plots\")\n",
    "print(\"7. [OK] Additional time series and categorical analyses\")\n",
    "print(\"8. [OK] Reports and visualizations saved\")\n",
    "\n",
    "if USE_CLAIMS_ONLY:\n",
    "    print(\"\\n‚ö†Ô∏è NOTE: Analysis performed on CLAIMS DATA ONLY (TotalClaims > 0)\")\n",
    "    print(\"   This is appropriate for analyzing actual claims patterns\")\n",
    "    print(\"   For overall portfolio analysis, use the full dataset\")\n",
    "\n",
    "print(\"\\nFILES GENERATED:\")\n",
    "print(\"‚Ä¢ reports/descriptive_statistics.csv\")\n",
    "print(\"‚Ä¢ reports/correlation_matrix.csv\")\n",
    "print(\"‚Ä¢ reports/outlier_report.json\")\n",
    "print(\"‚Ä¢ reports/data_sample.csv\")\n",
    "print(\"‚Ä¢ reports/eda_summary.txt\")\n",
    "\n",
    "print(\"\\nNEXT STEPS FOR OTHER RUBRICS:\")\n",
    "print(\"1. Check repository structure for Rubric 4 requirements\")\n",
    "print(\"2. Ensure DVC is properly set up (Rubric 2)\")\n",
    "print(\"3. Document Git practices in commit history (Rubric 3)\")\n",
    "print(\"4. Update README.md with EDA findings\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF EDA NOTEBOOK\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 7. BUSINESS INSIGHTS ANALYSIS (ANSWERING SPECIFIC QUESTIONS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUSINESS INSIGHTS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Add note about dataset type\n",
    "if USE_CLAIMS_ONLY:\n",
    "    print(\"‚ö†Ô∏è NOTE: Analyzing CLAIMS DATA ONLY (TotalClaims > 0)\")\n",
    "    print(\"This is appropriate for claims-specific questions\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# QUESTION 1: Loss Ratio Analysis by Various Dimensions\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüîç QUESTION 1: LOSS RATIO ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Ensure LossRatio exists or calculate it\n",
    "if 'LossRatio' not in df.columns and all(col in df.columns for col in ['TotalClaims', 'TotalPremium']):\n",
    "    print(\"‚ö†Ô∏è LossRatio column not found. Calculating from TotalClaims/TotalPremium...\")\n",
    "    df['LossRatio'] = df['TotalClaims'] / df['TotalPremium'].replace(0, np.nan)\n",
    "    df['LossRatio'] = df['LossRatio'].clip(lower=0, upper=10)\n",
    "\n",
    "if 'LossRatio' in df.columns:\n",
    "    # Overall Loss Ratio\n",
    "    overall_loss_ratio = df['LossRatio'].mean()\n",
    "    if pd.notna(overall_loss_ratio):\n",
    "        dataset_type = \"Claims Data\" if USE_CLAIMS_ONLY else \"Full Portfolio\"\n",
    "        print(f\"üìä Overall {dataset_type} Loss Ratio: {overall_loss_ratio:.2%}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Cannot calculate overall loss ratio - missing data\")\n",
    "    \n",
    "    # 1.1 Loss Ratio by Province\n",
    "    if 'Province' in df.columns:\n",
    "        print(\"\\nüìã Loss Ratio by Province:\")\n",
    "        print(\"-\" * 30)\n",
    "        province_loss = df.groupby('Province').agg({\n",
    "            'TotalPremium': 'sum',\n",
    "            'TotalClaims': 'sum',\n",
    "            'PolicyID': 'count'\n",
    "        }).rename(columns={'PolicyID': 'PolicyCount'})\n",
    "        \n",
    "        province_loss['CalculatedLossRatio'] = province_loss['TotalClaims'] / province_loss['TotalPremium'].replace(0, np.nan)\n",
    "        \n",
    "        # Filter out provinces with insufficient data\n",
    "        min_policies = 50  # Minimum number of policies for reliable analysis\n",
    "        province_loss = province_loss[province_loss['PolicyCount'] >= min_policies]\n",
    "        \n",
    "        if len(province_loss) > 0:\n",
    "            # Sort by Loss Ratio (highest to lowest)\n",
    "            province_sorted = province_loss.sort_values('CalculatedLossRatio', ascending=False)\n",
    "            \n",
    "            print(f\"Top 5 Highest Loss Ratio Provinces (min {min_policies} policies):\")\n",
    "            for i, (province, row) in enumerate(province_sorted.head(5).iterrows()):\n",
    "                if pd.notna(row['CalculatedLossRatio']):\n",
    "                    print(f\"  {i+1}. {province}: {row['CalculatedLossRatio']:.2%} \"\n",
    "                          f\"(Premium: ${row['TotalPremium']:,.0f}, Policies: {row['PolicyCount']:,})\")\n",
    "            \n",
    "            print(f\"\\nBottom 5 Lowest Loss Ratio Provinces (min {min_policies} policies):\")\n",
    "            for i, (province, row) in enumerate(province_sorted.tail(5).iterrows()):\n",
    "                if pd.notna(row['CalculatedLossRatio']):\n",
    "                    print(f\"  {i+1}. {province}: {row['CalculatedLossRatio']:.2%} \"\n",
    "                          f\"(Premium: ${row['TotalPremium']:,.0f}, Policies: {row['PolicyCount']:,})\")\n",
    "            \n",
    "            # Visualization\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            top_provinces = province_sorted.head(10)\n",
    "            \n",
    "            if len(top_provinces) > 0 and 'CalculatedLossRatio' in top_provinces.columns:\n",
    "                colors = plt.cm.RdYlGn(1 - top_provinces['CalculatedLossRatio'] / top_provinces['CalculatedLossRatio'].max())\n",
    "                plt.barh(range(len(top_provinces)), top_provinces['CalculatedLossRatio'], color=colors)\n",
    "                plt.yticks(range(len(top_provinces)), top_provinces.index)\n",
    "                plt.xlabel('Loss Ratio')\n",
    "                title = 'Top 10 Provinces by Loss Ratio (Higher = Worse)'\n",
    "                if USE_CLAIMS_ONLY:\n",
    "                    title += ' (Claims Data)'\n",
    "                plt.title(title)\n",
    "                plt.grid(True, alpha=0.3, axis='x')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No provinces with at least {min_policies} policies for reliable analysis\")\n",
    "    \n",
    "    # 1.2 Loss Ratio by Gender\n",
    "    if 'Gender' in df.columns:\n",
    "        print(\"\\nüìã Loss Ratio by Gender:\")\n",
    "        print(\"-\" * 30)\n",
    "        gender_loss = df.groupby('Gender').agg({\n",
    "            'TotalPremium': 'sum',\n",
    "            'TotalClaims': 'sum',\n",
    "            'PolicyID': 'count'\n",
    "        }).rename(columns={'PolicyID': 'PolicyCount'})\n",
    "        \n",
    "        gender_loss['LossRatio'] = gender_loss['TotalClaims'] / gender_loss['TotalPremium'].replace(0, np.nan)\n",
    "        \n",
    "        # Filter out genders with insufficient data\n",
    "        gender_loss = gender_loss[gender_loss['PolicyCount'] >= 10]\n",
    "        \n",
    "        if len(gender_loss) > 0:\n",
    "            print(gender_loss[['PolicyCount', 'TotalPremium', 'TotalClaims', 'LossRatio']].round(4))\n",
    "            \n",
    "            # Visualization\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            colors = ['lightblue', 'lightcoral', 'lightgreen']\n",
    "            gender_loss['LossRatio'].plot(kind='bar', color=colors[:len(gender_loss)])\n",
    "            title = 'Loss Ratio by Gender'\n",
    "            if USE_CLAIMS_ONLY:\n",
    "                title += ' (Claims Data)'\n",
    "            plt.title(title)\n",
    "            plt.xlabel('Gender')\n",
    "            plt.ylabel('Loss Ratio')\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Insufficient data for gender analysis\")\n",
    "    \n",
    "    # 1.3 Loss Ratio by VehicleType (if available)\n",
    "    # Check for vehicle-related columns\n",
    "    vehicle_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in \n",
    "                                                      ['vehicle', 'car', 'auto', 'motor', 'model', 'make'])]\n",
    "    vehicle_cols = [col for col in vehicle_cols if df[col].nunique() <= 50 and df[col].nunique() > 1]\n",
    "    \n",
    "    for vcol in vehicle_cols[:2]:  # Analyze first 2 vehicle-related columns\n",
    "        print(f\"\\nüìã Loss Ratio by {vcol}:\")\n",
    "        print(\"-\" * 30)\n",
    "        vehicle_loss = df.groupby(vcol).agg({\n",
    "            'TotalPremium': 'sum',\n",
    "            'TotalClaims': 'sum',\n",
    "            'PolicyID': 'count'\n",
    "        }).rename(columns={'PolicyID': 'PolicyCount'})\n",
    "        \n",
    "        vehicle_loss['LossRatio'] = vehicle_loss['TotalClaims'] / vehicle_loss['TotalPremium'].replace(0, np.nan)\n",
    "        \n",
    "        # Filter out categories with insufficient data\n",
    "        vehicle_loss = vehicle_loss[vehicle_loss['PolicyCount'] >= 5]\n",
    "        \n",
    "        if len(vehicle_loss) > 1:  # Need at least 2 categories for comparison\n",
    "            # Sort by Loss Ratio\n",
    "            vehicle_sorted = vehicle_loss.sort_values('LossRatio', ascending=False)\n",
    "            \n",
    "            print(f\"Top 5 Highest Loss Ratio {vcol} (min 5 policies):\")\n",
    "            for i, (vehicle, row) in enumerate(vehicle_sorted.head(5).iterrows()):\n",
    "                if pd.notna(row['LossRatio']):\n",
    "                    print(f\"  {i+1}. {vehicle}: {row['LossRatio']:.2%} \"\n",
    "                          f\"(Policies: {row['PolicyCount']:,})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# QUESTION 2: Distributions & Outlier Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüìä QUESTION 2: FINANCIAL DISTRIBUTIONS & OUTLIERS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2.1 Robust distribution analysis\n",
    "financial_cols = ['TotalPremium', 'TotalClaims', 'SumInsured', 'CustomValueEstimate']\n",
    "available_financial = [col for col in financial_cols if col in df.columns]\n",
    "\n",
    "if available_financial:\n",
    "    print(f\"Analyzing distributions for: {', '.join(available_financial)}\")\n",
    "    \n",
    "    # Create enhanced distribution plots with error handling\n",
    "    n_cols = min(2, len(available_financial))\n",
    "    n_rows = (len(available_financial) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(available_financial):\n",
    "        if idx < len(axes):\n",
    "            ax = axes[idx]\n",
    "            data = df[col].dropna()\n",
    "            \n",
    "            if len(data) > 10:  # Need enough data for meaningful analysis\n",
    "                # Check for variance\n",
    "                if data.std() > 0:  # Only plot if there's variance\n",
    "                    # Simple histogram without KDE\n",
    "                    ax.hist(data, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "                    \n",
    "                    # Add statistics\n",
    "                    stats_text = (f\"Mean: ${data.mean():,.0f}\\n\"\n",
    "                                f\"Median: ${data.median():,.0f}\\n\"\n",
    "                                f\"Std: ${data.std():,.0f}\\n\"\n",
    "                                f\"Skew: {data.skew():.2f}\\n\"\n",
    "                                f\"Count: {len(data):,}\")\n",
    "                    if USE_CLAIMS_ONLY and col == 'TotalClaims':\n",
    "                        stats_text += f\"\\nClaims Data Only\"\n",
    "                    \n",
    "                    ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,\n",
    "                           fontsize=8, verticalalignment='top', horizontalalignment='right',\n",
    "                           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "                    \n",
    "                    ax.set_title(f'Distribution of {col}', fontsize=11)\n",
    "                    ax.set_xlabel('Value ($)', fontsize=9)\n",
    "                    ax.set_ylabel('Frequency', fontsize=9)\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Insufficient variance\\nfor distribution plot', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_title(f'{col} (Constant Values)', fontsize=11)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'Insufficient data', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{col} (No Data)', fontsize=11)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(available_financial), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    title = 'Financial Variable Distributions'\n",
    "    if USE_CLAIMS_ONLY:\n",
    "        title += ' (Claims Data)'\n",
    "    plt.suptitle(title, fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 2.2 CustomValueEstimate outlier analysis (if available)\n",
    "if 'CustomValueEstimate' in df.columns:\n",
    "    print(\"\\nüîç CustomValueEstimate Outlier Analysis:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Calculate outlier thresholds\n",
    "    data = df['CustomValueEstimate'].dropna()\n",
    "    \n",
    "    if len(data) > 10 and data.std() > 0:  # Need enough data with variance\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        if IQR > 0:  # Check if IQR is valid\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "            outlier_percentage = (len(outliers) / len(data)) * 100\n",
    "            \n",
    "            print(f\"‚Ä¢ Total values: {len(data):,}\")\n",
    "            print(f\"‚Ä¢ Outliers (IQR method): {len(outliers):,} ({outlier_percentage:.1f}%)\")\n",
    "            print(f\"‚Ä¢ Outlier range: <${max(0, lower_bound):,.0f} or >${upper_bound:,.0f}\")\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"‚Ä¢ Mean of outliers: ${outliers.mean():,.0f}\")\n",
    "                print(f\"‚Ä¢ Max outlier: ${outliers.max():,.0f}\")\n",
    "            \n",
    "            # Impact analysis\n",
    "            if 'TotalClaims' in df.columns and len(outliers) > 0:\n",
    "                outlier_claims = df.loc[outliers.index, 'TotalClaims'].sum()\n",
    "                total_claims = df['TotalClaims'].sum()\n",
    "                if total_claims > 0:\n",
    "                    print(f\"‚Ä¢ Outliers account for {outlier_claims/total_claims*100:.1f}% of total claims\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Insufficient variance for outlier detection (IQR = 0)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Insufficient data or zero variance for analysis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# QUESTION 3: Temporal Trend Analysis (Enhanced)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüìÖ QUESTION 3: ENHANCED TEMPORAL TREND ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'TransactionMonth' in df.columns and 'TotalClaims' in df.columns:\n",
    "    try:\n",
    "        # Convert to datetime if needed\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['TransactionMonth']):\n",
    "            df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'])\n",
    "        \n",
    "        # Monthly aggregation with more metrics\n",
    "        monthly_data = df.groupby(df['TransactionMonth'].dt.to_period('M')).agg({\n",
    "            'TotalPremium': 'sum',\n",
    "            'TotalClaims': 'sum',\n",
    "            'PolicyID': 'count'\n",
    "        }).rename(columns={'PolicyID': 'PolicyCount'})\n",
    "        \n",
    "        monthly_data['CalculatedLossRatio'] = monthly_data['TotalClaims'] / monthly_data['TotalPremium'].replace(0, np.nan)\n",
    "        \n",
    "        # Calculate average claim (handle division by zero)\n",
    "        valid_months = monthly_data['PolicyCount'] > 0\n",
    "        monthly_data['AverageClaim'] = monthly_data['TotalClaims'] / monthly_data['PolicyCount'].where(valid_months, 1)\n",
    "        \n",
    "        # Calculate claim frequency (only for full dataset)\n",
    "        if not USE_CLAIMS_ONLY:\n",
    "            claims_by_month = df[df['TotalClaims'] > 0].groupby(df['TransactionMonth'].dt.to_period('M'))['PolicyID'].count()\n",
    "            monthly_data['ClaimFrequency'] = (claims_by_month / monthly_data['PolicyCount']).fillna(0)\n",
    "        \n",
    "        print(\"üìà Monthly Trend Summary:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"‚Ä¢ Time period: {monthly_data.index[0]} to {monthly_data.index[-1]}\")\n",
    "        print(f\"‚Ä¢ Total months: {len(monthly_data)}\")\n",
    "        if USE_CLAIMS_ONLY:\n",
    "            print(f\"‚Ä¢ Dataset: Claims Data Only\")\n",
    "        \n",
    "        # Calculate trends (only if we have enough data points)\n",
    "        if len(monthly_data) >= 2:\n",
    "            x_values = range(len(monthly_data))\n",
    "            \n",
    "            # Calculate premium trend\n",
    "            if monthly_data['TotalPremium'].std() > 0:\n",
    "                premium_trend = np.polyfit(x_values, monthly_data['TotalPremium'], 1)[0]\n",
    "                print(f\"\\nüìä Trend Analysis (slope):\")\n",
    "                print(f\"‚Ä¢ Premium trend: {'‚Üë' if premium_trend > 0 else '‚Üì'} ${premium_trend:,.0f}/month\")\n",
    "            \n",
    "            # Calculate claims trend\n",
    "            if monthly_data['TotalClaims'].std() > 0:\n",
    "                claims_trend = np.polyfit(x_values, monthly_data['TotalClaims'], 1)[0]\n",
    "                print(f\"‚Ä¢ Claims trend: {'‚Üë' if claims_trend > 0 else '‚Üì'} ${claims_trend:,.0f}/month\")\n",
    "            \n",
    "            # Calculate loss ratio trend\n",
    "            valid_loss_ratio = monthly_data['CalculatedLossRatio'].dropna()\n",
    "            if len(valid_loss_ratio) >= 2 and valid_loss_ratio.std() > 0:\n",
    "                loss_ratio_trend = np.polyfit(range(len(valid_loss_ratio)), valid_loss_ratio, 1)[0]\n",
    "                print(f\"‚Ä¢ Loss Ratio trend: {'‚Üë' if loss_ratio_trend > 0 else '‚Üì'} {loss_ratio_trend:.4f}/month\")\n",
    "        \n",
    "        # Enhanced visualization\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        metrics = [\n",
    "            ('TotalPremium', 'blue', 'Monthly Total Premium', 'Premium ($)'),\n",
    "            ('TotalClaims', 'red', 'Monthly Total Claims', 'Claims ($)'),\n",
    "            ('PolicyCount', 'green', 'Monthly Policy Count', 'Number of Policies'),\n",
    "            ('CalculatedLossRatio', 'purple', 'Monthly Loss Ratio', 'Loss Ratio'),\n",
    "            ('AverageClaim', 'orange', 'Average Claim Amount', 'Average Claim ($)'),\n",
    "        ]\n",
    "        \n",
    "        if not USE_CLAIMS_ONLY:\n",
    "            metrics.append(('ClaimFrequency', 'brown', 'Claim Frequency', 'Claim Frequency'))\n",
    "        \n",
    "        plot_count = 0\n",
    "        for idx, (metric, color, title, ylabel) in enumerate(metrics):\n",
    "            if idx < len(axes) and metric in monthly_data.columns:\n",
    "                ax = axes[plot_count]\n",
    "                if len(monthly_data[metric].dropna()) > 0:\n",
    "                    monthly_data[metric].plot(ax=ax, color=color, marker='o', linewidth=2)\n",
    "                    ax.set_title(title, fontsize=12)\n",
    "                    ax.set_ylabel(ylabel, fontsize=10)\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                    plot_count += 1\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'No data available', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_title(title, fontsize=12)\n",
    "                    plot_count += 1\n",
    "        \n",
    "        # Hide any empty axes\n",
    "        for idx in range(plot_count, len(axes)):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        title = 'Comprehensive Monthly Insurance Trends'\n",
    "        if USE_CLAIMS_ONLY:\n",
    "            title += ' (Claims Data)'\n",
    "        plt.suptitle(title, fontsize=16, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not perform enhanced temporal analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# QUESTION 4: Vehicle Make/Model Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nüöó QUESTION 4: VEHICLE MAKE/MODEL ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Identify potential vehicle-related columns\n",
    "vehicle_make_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['make', 'model', 'manufacturer', 'brand'])]\n",
    "vehicle_type_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['type', 'category', 'class'])]\n",
    "\n",
    "print(f\"Potential vehicle make/model columns: {vehicle_make_cols}\")\n",
    "print(f\"Potential vehicle type columns: {vehicle_type_cols}\")\n",
    "\n",
    "# Analyze available vehicle columns\n",
    "vehicle_analysis_results = {}\n",
    "\n",
    "for vcol in vehicle_make_cols + vehicle_type_cols:\n",
    "    if vcol in df.columns:\n",
    "        unique_count = df[vcol].nunique()\n",
    "        # Only analyze if we have reasonable number of categories and data\n",
    "        if 2 <= unique_count <= 50 and df[vcol].count() > 100:  \n",
    "            print(f\"\\nüìä Analyzing {vcol} ({unique_count} unique values, {df[vcol].count():,} records):\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            try:\n",
    "                vehicle_stats = df.groupby(vcol).agg({\n",
    "                    'TotalPremium': ['count', 'sum', 'mean'],\n",
    "                    'TotalClaims': ['sum', 'mean'],\n",
    "                })\n",
    "                \n",
    "                # Flatten column names\n",
    "                vehicle_stats.columns = [f'{col[0]}_{col[1]}' for col in vehicle_stats.columns]\n",
    "                \n",
    "                # Calculate Loss Ratio (handle division by zero)\n",
    "                vehicle_stats['LossRatio'] = vehicle_stats['TotalClaims_sum'] / vehicle_stats['TotalPremium_sum'].replace(0, np.nan)\n",
    "                \n",
    "                # Filter out categories with insufficient data\n",
    "                vehicle_stats = vehicle_stats[vehicle_stats['TotalPremium_count'] >= 10]  # At least 10 policies\n",
    "                \n",
    "                if len(vehicle_stats) > 1:  # Need at least 2 categories for comparison\n",
    "                    # Sort by different metrics\n",
    "                    by_loss_ratio = vehicle_stats.sort_values('LossRatio', ascending=False)\n",
    "                    by_claims = vehicle_stats.sort_values('TotalClaims_sum', ascending=False)\n",
    "                    by_premium = vehicle_stats.sort_values('TotalPremium_sum', ascending=False)\n",
    "                    \n",
    "                    print(f\"Top 5 by Loss Ratio (Highest Risk):\")\n",
    "                    for i, (idx, row) in enumerate(by_loss_ratio.head(5).iterrows()):\n",
    "                        if pd.notna(row['LossRatio']):\n",
    "                            print(f\"  {i+1}. {idx}: {row['LossRatio']:.2%} \"\n",
    "                                  f\"(Claims: ${row['TotalClaims_sum']:,.0f}, Policies: {row['TotalPremium_count']:,})\")\n",
    "                    \n",
    "                    print(f\"\\nTop 5 by Total Claims (Highest Cost):\")\n",
    "                    for i, (idx, row) in enumerate(by_claims.head(5).iterrows()):\n",
    "                        print(f\"  {i+1}. {idx}: ${row['TotalClaims_sum']:,.0f} \"\n",
    "                              f\"(Policies: {row['TotalPremium_count']:,})\")\n",
    "                    \n",
    "                    print(f\"\\nTop 5 by Total Premium (Highest Revenue):\")\n",
    "                    for i, (idx, row) in enumerate(by_premium.head(5).iterrows()):\n",
    "                        print(f\"  {i+1}. {idx}: ${row['TotalPremium_sum']:,.0f} \"\n",
    "                              f\"(Policies: {row['TotalPremium_count']:,})\")\n",
    "                    \n",
    "                    # Store for visualization\n",
    "                    vehicle_analysis_results[vcol] = vehicle_stats\n",
    "                    \n",
    "                    # Visualization (only if we have data)\n",
    "                    if len(by_loss_ratio) > 0 and len(by_claims) > 0:\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "                        \n",
    "                        # Top 10 by Loss Ratio\n",
    "                        top_loss = by_loss_ratio.head(10)\n",
    "                        if len(top_loss) > 0:\n",
    "                            colors = plt.cm.RdYlGn(1 - top_loss['LossRatio'] / top_loss['LossRatio'].max())\n",
    "                            axes[0].barh(range(len(top_loss)), top_loss['LossRatio'], color=colors)\n",
    "                            axes[0].set_yticks(range(len(top_loss)))\n",
    "                            axes[0].set_yticklabels(top_loss.index)\n",
    "                            axes[0].set_xlabel('Loss Ratio')\n",
    "                            title = f'Top 10 {vcol} by Loss Ratio'\n",
    "                            if USE_CLAIMS_ONLY:\n",
    "                                title += ' (Claims)'\n",
    "                            axes[0].set_title(title)\n",
    "                            axes[0].grid(True, alpha=0.3, axis='x')\n",
    "                        \n",
    "                        # Top 10 by Total Claims\n",
    "                        top_claims = by_claims.head(10)\n",
    "                        if len(top_claims) > 0:\n",
    "                            axes[1].bar(range(len(top_claims)), top_claims['TotalClaims_sum'] / 1000, color='lightcoral')\n",
    "                            axes[1].set_xticks(range(len(top_claims)))\n",
    "                            axes[1].set_xticklabels(top_claims.index, rotation=45, ha='right')\n",
    "                            axes[1].set_ylabel('Total Claims (Thousands $)')\n",
    "                            title = f'Top 10 {vcol} by Total Claims'\n",
    "                            if USE_CLAIMS_ONLY:\n",
    "                                title += ' (Claims)'\n",
    "                            axes[1].set_title(title)\n",
    "                            axes[1].grid(True, alpha=0.3, axis='y')\n",
    "                        \n",
    "                        plt.suptitle(f'Vehicle Analysis: {vcol}', fontsize=14, y=1.02)\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error analyzing {vcol}: {e}\")\n",
    "                continue\n",
    "\n",
    "# If no specific vehicle columns found, check for general vehicle info\n",
    "if not vehicle_analysis_results and 'VehicleAge' in df.columns:\n",
    "    print(\"\\nüìä Vehicle Age Analysis (since specific make/model columns not found):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Create age bins\n",
    "        df['VehicleAgeGroup'] = pd.cut(df['VehicleAge'], \n",
    "                                       bins=[0, 3, 5, 7, 10, 15, 30, 100], \n",
    "                                       labels=['0-3', '4-5', '6-7', '8-10', '11-15', '16-30', '30+'])\n",
    "        \n",
    "        age_stats = df.groupby('VehicleAgeGroup').agg({\n",
    "            'TotalPremium': ['count', 'sum', 'mean'],\n",
    "            'TotalClaims': ['sum', 'mean'],\n",
    "            'LossRatio': 'mean'\n",
    "        }).round(4)\n",
    "        \n",
    "        print(\"Vehicle Age Group Analysis:\")\n",
    "        print(age_stats)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error in vehicle age analysis: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 8. BUSINESS RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ KEY RECOMMENDATIONS BASED ON ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if USE_CLAIMS_ONLY:\n",
    "    print(\"üìä Analysis based on CLAIMS DATA ONLY (policies with TotalClaims > 0):\")\n",
    "    print(\"  ‚Ä¢ Insights reflect actual claim patterns, not overall portfolio\")\n",
    "    print(\"  ‚Ä¢ Use for claims management and risk assessment\")\n",
    "    print(\"  ‚Ä¢ For pricing decisions, combine with full portfolio analysis\\n\")\n",
    "\n",
    "# Recommendation 1: Based on Loss Ratio analysis\n",
    "if 'Province' in df.columns and 'LossRatio' in df.columns:\n",
    "    try:\n",
    "        province_loss = df.groupby('Province')['LossRatio'].mean()\n",
    "        if len(province_loss) > 0:\n",
    "            high_loss_provinces = province_loss.nlargest(3)\n",
    "            print(\"1. üî¥ High Risk Areas (Based on Loss Ratio):\")\n",
    "            for province, loss_ratio in high_loss_provinces.items():\n",
    "                if pd.notna(loss_ratio) and loss_ratio > 0:\n",
    "                    if USE_CLAIMS_ONLY:\n",
    "                        print(f\"   ‚Ä¢ {province}: High claims loss ratio ({loss_ratio:.2%}) - review claims patterns\")\n",
    "                    else:\n",
    "                        print(f\"   ‚Ä¢ {province}: Consider premium adjustments (Current Loss Ratio: {loss_ratio:.2%})\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Recommendation 2: Based on temporal trends\n",
    "if 'TransactionMonth' in df.columns and 'TotalClaims' in df.columns:\n",
    "    print(\"\\n2. üìà Temporal Recommendations:\")\n",
    "    try:\n",
    "        monthly_data = df.groupby(df['TransactionMonth'].dt.to_period('M'))['TotalClaims'].sum()\n",
    "        if len(monthly_data) >= 6:\n",
    "            recent_avg = monthly_data[-6:].mean()\n",
    "            previous_avg = monthly_data[-12:-6].mean() if len(monthly_data) >= 12 else monthly_data[:-6].mean()\n",
    "            trend = \"increasing\" if recent_avg > previous_avg else \"decreasing\"\n",
    "            if USE_CLAIMS_ONLY:\n",
    "                print(f\"   ‚Ä¢ Claim amounts are {trend} recently. Monitor for seasonal patterns in claims.\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ Claim amounts are {trend} recently. Monitor for seasonal patterns.\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Recommendation 3: Based on vehicle analysis\n",
    "if vehicle_analysis_results:\n",
    "    print(\"\\n3. üöó Vehicle Portfolio Recommendations:\")\n",
    "    for vcol, stats in vehicle_analysis_results.items():\n",
    "        if 'LossRatio' in stats.columns:\n",
    "            high_risk = stats.nlargest(3, 'LossRatio')\n",
    "            for idx, row in high_risk.iterrows():\n",
    "                if pd.notna(row['LossRatio']) and row['LossRatio'] > 0.5:  # 50% loss ratio threshold\n",
    "                    if USE_CLAIMS_ONLY:\n",
    "                        print(f\"   ‚Ä¢ {vcol}: {idx} has high claims loss ratio ({row['LossRatio']:.2%})\")\n",
    "                    else:\n",
    "                        print(f\"   ‚Ä¢ {vcol}: {idx} has high loss ratio ({row['LossRatio']:.2%})\")\n",
    "\n",
    "# Recommendation 4: Based on dataset type\n",
    "if USE_CLAIMS_ONLY:\n",
    "    print(\"\\n4. üìä Claims Data Specific Recommendations:\")\n",
    "    print(\"   ‚Ä¢ Use this analysis for claims reserving and claims handling optimization\")\n",
    "    print(\"   ‚Ä¢ Identify high-frequency claim types for preventive measures\")\n",
    "    print(\"   ‚Ä¢ Analyze claim amounts to set appropriate excess levels\")\n",
    "else:\n",
    "    print(\"\\n4. ‚ö†Ô∏è Risk Management Recommendations:\")\n",
    "    print(\"   ‚Ä¢ Review policies with extreme CustomValueEstimate outliers\")\n",
    "    print(\"   ‚Ä¢ Consider implementing value caps for high-risk assets\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01eb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 9. UPDATE SUMMARY REPORT WITH BUSINESS INSIGHTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UPDATING SUMMARY REPORT WITH BUSINESS INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Update the summary report\n",
    "try:\n",
    "    with open('reports/eda_summary.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"BUSINESS INSIGHTS & ANSWERS TO QUESTIONS\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"QUESTION 1: LOSS RATIO ANALYSIS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if 'LossRatio' in df.columns:\n",
    "            overall_lr = df['LossRatio'].mean()\n",
    "            if pd.notna(overall_lr):\n",
    "                if USE_CLAIMS_ONLY:\n",
    "                    f.write(f\"‚Ä¢ Loss Ratio for Claims Data: {overall_lr:.2%}\\n\")\n",
    "                else:\n",
    "                    f.write(f\"‚Ä¢ Overall Portfolio Loss Ratio: {overall_lr:.2%}\\n\")\n",
    "            if 'Province' in df.columns:\n",
    "                province_stats = df.groupby('Province')['LossRatio'].mean()\n",
    "                if len(province_stats) > 0:\n",
    "                    f.write(f\"‚Ä¢ Highest Loss Ratio Province: {province_stats.idxmax()} ({province_stats.max():.2%})\\n\")\n",
    "                    f.write(f\"‚Ä¢ Lowest Loss Ratio Province: {province_stats.idxmin()} ({province_stats.min():.2%})\\n\")\n",
    "        \n",
    "        f.write(\"\\nQUESTION 2: FINANCIAL DISTRIBUTIONS & OUTLIERS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if 'CustomValueEstimate' in df.columns:\n",
    "            data = df['CustomValueEstimate'].dropna()\n",
    "            if len(data) > 10 and data.std() > 0:\n",
    "                Q1 = data.quantile(0.25)\n",
    "                Q3 = data.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                if IQR > 0:\n",
    "                    outliers = data[(data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))]\n",
    "                    f.write(f\"‚Ä¢ CustomValueEstimate outliers: {len(outliers):,} ({len(outliers)/len(data)*100:.1f}%)\\n\")\n",
    "        \n",
    "        f.write(\"\\nQUESTION 3: TEMPORAL TRENDS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if 'TransactionMonth' in df.columns:\n",
    "            f.write(f\"‚Ä¢ Data covers: {df['TransactionMonth'].min()} to {df['TransactionMonth'].max()}\\n\")\n",
    "            if 'TotalClaims' in df.columns:\n",
    "                monthly_claims = df.groupby(df['TransactionMonth'].dt.to_period('M'))['TotalClaims'].sum()\n",
    "                if len(monthly_claims) > 1:\n",
    "                    f.write(f\"‚Ä¢ Claim trend: {('Increasing' if monthly_claims.iloc[-1] > monthly_claims.iloc[0] else 'Decreasing')}\\n\")\n",
    "        \n",
    "        f.write(\"\\nQUESTION 4: VEHICLE ANALYSIS\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if vehicle_analysis_results:\n",
    "            for vcol, stats in vehicle_analysis_results.items():\n",
    "                if 'LossRatio' in stats.columns:\n",
    "                    high_risk = stats.nlargest(1, 'LossRatio')\n",
    "                    for idx, row in high_risk.iterrows():\n",
    "                        if pd.notna(row['LossRatio']):\n",
    "                            f.write(f\"‚Ä¢ Highest risk {vcol}: {idx} (Loss Ratio: {row['LossRatio']:.2%})\\n\")\n",
    "    \n",
    "    print(\"‚úÖ Business insights added to summary report\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error updating summary report: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 10. FINAL COMPLETION CHECK\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL COMPLETION CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ ALL QUESTIONS ANSWERED:\")\n",
    "print(\"1. ‚úÖ Loss Ratio analysis by Province, Gender, and Vehicle types\")\n",
    "print(\"2. ‚úÖ Detailed financial distributions and outlier analysis\")\n",
    "print(\"3. ‚úÖ Enhanced temporal trend analysis with claim frequency/severity\")\n",
    "print(\"4. ‚úÖ Vehicle make/model risk assessment\")\n",
    "\n",
    "if USE_CLAIMS_ONLY:\n",
    "    print(\"\\nüìä SPECIAL NOTE:\")\n",
    "    print(\"‚Ä¢ Analysis performed on CLAIMS DATA ONLY (TotalClaims > 0)\")\n",
    "    print(\"‚Ä¢ This provides insights into actual claims patterns\")\n",
    "    print(\"‚Ä¢ For overall portfolio analysis, run with full dataset\")\n",
    "\n",
    "print(\"\\nüìÅ ADDITIONAL FILES GENERATED:\")\n",
    "print(\"‚Ä¢ Enhanced visualizations for business questions\")\n",
    "print(\"‚Ä¢ Updated summary report with business insights\")\n",
    "print(\"‚Ä¢ Risk assessment recommendations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE - ALL BUSINESS QUESTIONS ANSWERED!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
